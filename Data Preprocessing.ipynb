{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0497e075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f985b25",
   "metadata": {},
   "source": [
    "AUDIO PROCESSING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a192b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This Load audio with consistent sample rate,padding and convert stero to mono\n",
    "   here it would be called once for each audio file you can modify it like you want for multiple files'''\n",
    "\n",
    "def load_audio(file_path, sample_rate=22050, min_duration=5.0):\n",
    "\n",
    "    min_samples = int(sample_rate * min_duration)\n",
    "    audio, sr = sf.read(file_path)\n",
    "    \n",
    "    # if its stero converts to mono\n",
    "    if len(audio.shape) > 1:\n",
    "        audio = np.mean(audio, axis=1)\n",
    "    \n",
    "    # this is to resample \n",
    "    if sr != sample_rate:\n",
    "        audio = librosa.resample(audio, orig_sr=sr, target_sr=sample_rate)\n",
    "    \n",
    "    # its for padding\n",
    "    if len(audio) < min_samples:\n",
    "        repeats = (min_samples // len(audio)) + 1\n",
    "        audio = np.tile(audio, repeats)[:min_samples]\n",
    "    \n",
    "    return audio.astype('float32') # choose this coz 32-bit floating point format Compatible with libraries like PyTorch, Librosa, and your model\n",
    "\n",
    "class MelSpectrogramConverter:\n",
    "\n",
    "    #to convert Converts audio to Mel-spectrograms \n",
    "\n",
    "    def __init__(self, sample_rate=22050, n_mels=128, n_fft=2048, hop_length=512):\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mels = n_mels\n",
    "        self.n_fft = n_fft\n",
    "        self.hop_length = hop_length       \n",
    "        self.mel_basis = librosa.filters.mel(\n",
    "            sr=sample_rate,\n",
    "            n_fft=n_fft,\n",
    "            n_mels=n_mels,\n",
    "            fmin=20,\n",
    "            fmax=sample_rate//2\n",
    "        )\n",
    "    \n",
    "    def __call__(self, audio):\n",
    "        stft = librosa.stft(\n",
    "            audio,\n",
    "            n_fft=self.n_fft,\n",
    "            hop_length=self.hop_length,\n",
    "            win_length=self.n_fft\n",
    "        )\n",
    "    \n",
    "        mel_spec = np.dot(self.mel_basis, np.abs(stft)**2)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        \n",
    "        mel_spec_db = (mel_spec_db - np.min(mel_spec_db)) / (np.max(mel_spec_db) - np.min(mel_spec_db))\n",
    "        return 2 * mel_spec_db - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d8ae40",
   "metadata": {},
   "source": [
    "DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f5cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling frequency and time masking to spectrograms\n",
    "\n",
    "class SpecAugment:\n",
    "    \"\"\"Applies frequency and time masking to spectrograms\"\"\"\n",
    "    def __init__(self, freq_mask_max=0.15, time_mask_max=0.20):\n",
    "        self.freq_mask_max = freq_mask_max\n",
    "        self.time_mask_max = time_mask_max\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        spec = spec.copy()\n",
    "        n_mels, n_time = spec.shape\n",
    "        \n",
    "        # Frequency masking\n",
    "        if self.freq_mask_max > 0:\n",
    "            max_freq_bands = int(n_mels * self.freq_mask_max)\n",
    "            freq_bands = random.randint(1, max_freq_bands)\n",
    "            freq_start = random.randint(0, n_mels - freq_bands)\n",
    "            spec[freq_start:freq_start+freq_bands, :] = np.min(spec)\n",
    "        \n",
    "        # Time masking\n",
    "        if self.time_mask_max > 0:\n",
    "            max_time_steps = int(n_time * self.time_mask_max)\n",
    "            time_steps = random.randint(1, max_time_steps)\n",
    "            time_start = random.randint(0, n_time - time_steps)\n",
    "            spec[:, time_start:time_start+time_steps] = np.min(spec)\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "# It Mixes two audio samples with adjustable ratio\n",
    "\n",
    "class AudioMixer:\n",
    "    \n",
    "    def __init__(self, alpha=0.4, mix_prob=0.5):\n",
    "        self.alpha = alpha\n",
    "        self.mix_prob = mix_prob\n",
    "    \n",
    "    def __call__(self, dataset, index, spec, label):\n",
    "        if random.random() > self.mix_prob:\n",
    "            return spec, label\n",
    "            \n",
    "       \n",
    "        idx2 = random.randint(0, len(dataset) - 1)\n",
    "        spec2, label2 = dataset.get_sample(idx2)\n",
    "        \n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        \n",
    "        mixed_spec = lam * spec + (1 - lam) * spec2\n",
    "        mixed_label = lam * label + (1 - lam) * label2\n",
    "        \n",
    "        return mixed_spec, mixed_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0c27be",
   "metadata": {},
   "source": [
    "DATASET HANDLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5641b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Handling FSD50K dataset processing and augmentation\n",
    "\n",
    "class FSD50KDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, manifest_path, labels_map, sample_rate=22050, \n",
    "                 n_mels=128, min_duration=5.0, augment=False):\n",
    "       \n",
    "        with open(labels_map, 'r') as f:\n",
    "            self.labels_map = json.load(f)\n",
    "        \n",
    "        self.df = pd.read_csv(manifest_path)\n",
    "        self.audio_paths = self.df['files'].values\n",
    "        self.labels = self.df['labels'].values\n",
    "        self.num_classes = len(self.labels_map)\n",
    "\n",
    "        self.sample_rate = sample_rate\n",
    "        self.n_mels = n_mels\n",
    "        self.min_duration = min_duration\n",
    "        self.augment = augment\n",
    "        \n",
    "        self.mel_converter = MelSpectrogramConverter(\n",
    "            sample_rate=sample_rate,\n",
    "            n_mels=n_mels\n",
    "        )\n",
    "        \n",
    "        self.spec_augment = SpecAugment() if augment else None\n",
    "        self.audio_mixer = AudioMixer() if augment else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.audio_paths)\n",
    "\n",
    "#Get sample without augmentation (for mixing)\n",
    "\n",
    "    def get_sample(self, idx):\n",
    "        \"\"\"Get sample without augmentation (for mixing)\"\"\"\n",
    "        audio = load_audio(\n",
    "            self.audio_paths[idx],\n",
    "            self.sample_rate,\n",
    "            self.min_duration\n",
    "        )\n",
    "        return (\n",
    "            self.mel_converter(audio),\n",
    "            self._parse_labels(self.labels[idx])\n",
    "        )\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        audio = load_audio(\n",
    "            self.audio_paths[idx],\n",
    "            self.sample_rate,\n",
    "            self.min_duration\n",
    "        )\n",
    "        mel_spec = self.mel_converter(audio)\n",
    "        \n",
    "        label = self._parse_labels(self.labels[idx])\n",
    "        \n",
    "        # Applying mix augmentation\n",
    "        if self.augment and self.audio_mixer:\n",
    "            mel_spec, label = self.audio_mixer(self, idx, mel_spec, label)\n",
    "        \n",
    "        # Applying spectrogram augmentation\n",
    "        if self.augment and self.spec_augment:\n",
    "            mel_spec = self.spec_augment(mel_spec)\n",
    "        \n",
    "        # Convert to tensor and add channel dimension coz CNNs require input in [channels, height, width] format, and this line ensures that\n",
    "        return (\n",
    "            torch.tensor(mel_spec).unsqueeze(0),  # Shape: [1, n_mels, time]\n",
    "            torch.tensor(label)\n",
    "        )\n",
    "    \n",
    "    #Convert label string to multi-hot vector\n",
    "    \n",
    "    def _parse_labels(self, label_str):\n",
    "    \n",
    "        label_vector = np.zeros(self.num_classes)\n",
    "        for label in label_str.split(','):\n",
    "            label_vector[self.labels_map[label]] = 1\n",
    "        return label_vector"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
