{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import chain, combinations\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import threading\n",
    "from multiprocessing import Manager\n",
    "import gc\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing our spectrogram using imagenet stats\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling frequency and time masking to spectrograms\n",
    "\n",
    "class SpecAugment:\n",
    "    \"\"\"Applies frequency and time masking to spectrograms\"\"\"\n",
    "    def __init__(self, freq_mask_max=0.15, time_mask_max=0.20):\n",
    "        self.freq_mask_max = freq_mask_max\n",
    "        self.time_mask_max = time_mask_max\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        spec = spec.clone()\n",
    "        n_mels, n_time = spec.shape\n",
    "        \n",
    "        # Frequency masking\n",
    "        if self.freq_mask_max > 0:\n",
    "            max_freq_bands = int(n_mels * self.freq_mask_max)\n",
    "            freq_bands = random.randint(1, max_freq_bands)\n",
    "            freq_start = random.randint(0, n_mels - freq_bands)\n",
    "            spec[freq_start:freq_start+freq_bands, :] = spec.min()\n",
    "        \n",
    "        # Time masking\n",
    "        if self.time_mask_max > 0:\n",
    "            max_time_steps = int(n_time * self.time_mask_max)\n",
    "            time_steps = random.randint(1, max_time_steps)\n",
    "            time_start = random.randint(0, n_time - time_steps)\n",
    "            spec[:, time_start:time_start+time_steps] = spec.min()\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "# It Mixes two audio samples with adjustable ratio\n",
    "\n",
    "class AudioMixer:\n",
    "    \n",
    "    def __init__(self, alpha=0.5, mix_prob=0.5, min_mix_ratio=0.3):\n",
    "        self.alpha = alpha\n",
    "        self.mix_prob = mix_prob\n",
    "        self.min_mix_ratio = min_mix_ratio\n",
    "\n",
    "    def __call__(self, spec1, label1, specsList, labelsList):\n",
    "        if random.random() > self.mix_prob:\n",
    "            return spec1, label1\n",
    "        idx2 = random.randint(0, specsList.shape[0] - 1)\n",
    "        spec2 = specsList[idx2]\n",
    "        label2 = labelsList[idx2]\n",
    "        if spec1.shape != spec2.shape:\n",
    "            raise ValueError(\"Spectrograms is somehow not in same shape\")\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        lam = lam * 1.0 * (1.0 - 2 * self.min_mix_ratio) + self.min_mix_ratio\n",
    "        mixed_spec = lam * spec1 + (1 - lam) * spec2\n",
    "        mixed_label = torch.clamp(label1 + label2, 0, 1)\n",
    "        return mixed_spec, mixed_label\n",
    "    \n",
    "spec_augment = SpecAugment()\n",
    "audio_mixer = AudioMixer()\n",
    "\n",
    "def batch_augment(specsList, labelsList):\n",
    "    augmented_specs = []\n",
    "    augmented_labels = []\n",
    "    N = specsList.shape[0]\n",
    "    for i in range(N):\n",
    "        spec = specsList[i]\n",
    "        label = labelsList[i]\n",
    "        spec, label = audio_mixer(spec, label, specsList, labelsList)\n",
    "        spec = spec_augment(spec)\n",
    "        augmented_specs.append(spec)\n",
    "        augmented_labels.append(label)\n",
    "    augmented_specs = torch.stack(augmented_specs)\n",
    "    augmented_labels = torch.stack(augmented_labels)\n",
    "    augmented_specs = augmented_specs.unsqueeze(1).expand(-1, 3, -1, -1)\n",
    "    augmented_specs = (augmented_specs - mean) / std\n",
    "    return augmented_specs, augmented_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShardedEpisodicDataset():\n",
    "  def __init__(self, data_paths, meta_path, min_n_way, try_k_shot, try_n_query, split=\"train\", test_split=0.1, val_split=0.1, split_seed=33):\n",
    "    self.data_paths = data_paths\n",
    "    self.min_n_way = min_n_way\n",
    "    self.try_k_shot = try_k_shot\n",
    "    self.try_n_query = try_n_query\n",
    "\n",
    "    # load metadata\n",
    "    meta = torch.load(meta_path)\n",
    "    self.rel_idxs = meta['rel_idxs']\n",
    "    self.n_examples = self.rel_idxs[-1] + 1\n",
    "    meta_class_idxs = meta['class_idxs']\n",
    "    self.n_classes = len(meta_class_idxs)\n",
    "\n",
    "    # filter classes based on split type\n",
    "    all_idxs = list(range(self.n_examples))\n",
    "    train_idxs, test_idxs = train_test_split(all_idxs, test_size=test_split + val_split, random_state=split_seed)\n",
    "    test_idxs, val_idxs = train_test_split(test_idxs, test_size=val_split / (test_split + val_split), random_state=split_seed)\n",
    "    print(f\"train_size : {len(train_idxs)}, test_size : {len(test_idxs)}, val_size : {len(val_idxs)}\")\n",
    "    if split == \"train\":\n",
    "      valid_idxs = set(train_idxs)\n",
    "    elif split == \"test\":\n",
    "      valid_idxs = set(test_idxs)\n",
    "    elif split == 'val':\n",
    "      valid_idxs = set(val_idxs)\n",
    "    else:\n",
    "      raise ValueError(\"Critical: split is not train, test or val\")\n",
    "\n",
    "    self.class_idxs = [[i.item() for i in meta_class_idxs[c] if i.item() in valid_idxs] for c in range(self.n_classes)]\n",
    "\n",
    "    # filter valid classes\n",
    "    self.valid_classes = [\n",
    "      c for c, indices in enumerate(self.class_idxs)\n",
    "      if len(indices) >= self.try_k_shot + self.try_n_query\n",
    "    ]\n",
    "\n",
    "    print(f\"{len(self.valid_classes)} of {len(self.class_idxs)} classes have atleast try_k_shot + try_n_query ({self.try_k_shot + self.try_n_query}) examples\")\n",
    "\n",
    "    if len(self.valid_classes) < self.min_n_way:\n",
    "      raise ValueError(f\"critical: try_k_shot + try_n_query is too big or min_n_way is too big, there are {len(self.valid_classes)} valid classes\")\n",
    "\n",
    "    # cache management\n",
    "    self.cache_size = 1\n",
    "    self.manager = Manager()\n",
    "    self.cache = self.manager.dict()\n",
    "    self.lock = threading.Lock()\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.valid_classes) * self.try_k_shot # cuz this number sounds good, idk the standards of dataset length when its episodic\n",
    "\n",
    "  def _get_idxs(self, idx):\n",
    "    # binary search on shard to find shard\n",
    "    low, high = 0, len(self.rel_idxs) - 1\n",
    "    while (low < high):\n",
    "      mid = (low + high) // 2\n",
    "      if self.rel_idxs[mid] < idx:\n",
    "        low = mid + 1\n",
    "      else:\n",
    "        high = mid\n",
    "    shard_idx = low\n",
    "    \n",
    "    if (shard_idx == 0):\n",
    "      abs_idx = idx\n",
    "    else:\n",
    "      abs_idx = idx - self.rel_idxs[shard_idx - 1] - 1\n",
    "    return shard_idx, abs_idx\n",
    "\n",
    "  def _load_shard(self, shard_idx):\n",
    "    shard_path = self.data_paths[shard_idx]\n",
    "    \n",
    "    with self.lock:\n",
    "      # Check if shard is already in cache\n",
    "      if shard_path in self.cache:\n",
    "        return self.cache[shard_path]\n",
    "            \n",
    "      # If cache is full, remove one item\n",
    "      if len(self.cache) >= self.cache_size:\n",
    "        # More predictable eviction strategy\n",
    "        oldest_key = next(iter(self.cache))\n",
    "        self.cache.pop(oldest_key)\n",
    "            \n",
    "      # Load the shard and store in cache\n",
    "      shard = torch.load(shard_path)\n",
    "      self.cache[shard_path] = shard\n",
    "        \n",
    "    return shard\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    # Choose random subset of n_way classes\n",
    "    selected_classes = random.sample(self.valid_classes, self.min_n_way)\n",
    "\n",
    "    support_indices, query_indices = [], []\n",
    "\n",
    "    for c in selected_classes:\n",
    "      indices = self.class_idxs[c]\n",
    "      if not indices:\n",
    "        continue\n",
    "      selected_indices = random.sample(indices, self.try_k_shot + self.try_n_query)\n",
    "      support_indices.extend(selected_indices[:self.try_k_shot])\n",
    "      query_indices.extend(selected_indices[self.try_k_shot:])\n",
    "\n",
    "    support_indices = torch.tensor(support_indices, dtype=torch.long)\n",
    "    query_indices = torch.tensor(query_indices, dtype=torch.long)\n",
    "\n",
    "    unique_shards = set(self._get_idxs(i)[0] for i in support_indices.tolist() + query_indices.tolist())\n",
    "    shard_data = {shard_idx: self._load_shard(shard_idx) for shard_idx in unique_shards}\n",
    "\n",
    "    # Fetch data/labels from those shards\n",
    "    support_data = torch.cat([shard_data[self._get_idxs(i)[0]]['imgs'][self._get_idxs(i)[1]].unsqueeze(0) for i in support_indices])\n",
    "    support_label = torch.cat([shard_data[self._get_idxs(i)[0]]['lbls'][self._get_idxs(i)[1]].unsqueeze(0) for i in support_indices])\n",
    "    query_data = torch.cat([shard_data[self._get_idxs(i)[0]]['imgs'][self._get_idxs(i)[1]].unsqueeze(0) for i in query_indices])\n",
    "    query_label = torch.cat([shard_data[self._get_idxs(i)[0]]['lbls'][self._get_idxs(i)[1]].unsqueeze(0) for i in query_indices])\n",
    "\n",
    "    support_data, support_label = batch_augment(support_data, support_label)\n",
    "    query_data, query_label = batch_augment(query_data, query_label)\n",
    "\n",
    "    return {\n",
    "      'support_data': support_data, # (~n_way * ~k_shot, C, H, W)\n",
    "      'support_label': support_label, # (~n_way * ~k_shot, num_classes)\n",
    "      'query_data': query_data, # (~n_way * ~n_query, C, H, W)\n",
    "      'query_label': query_label # (~n_way * ~n_query, num_classes)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Temp\\ipykernel_9252\\1539366073.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta = torch.load(meta_path)\n"
     ]
    }
   ],
   "source": [
    "data_paths = list(Path('./data/processed_pth_files/').rglob('*.pth'))\n",
    "data_paths.sort()\n",
    "meta_path = data_paths.pop()\n",
    "meta = torch.load(meta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Temp\\ipykernel_9252\\1519225210.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta = torch.load(meta_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size : 800, test_size : 100, val_size : 100\n",
      "51 of 200 classes have atleast try_k_shot + try_n_query (10) examples\n",
      "train_size : 800, test_size : 100, val_size : 100\n",
      "12 of 200 classes have atleast try_k_shot + try_n_query (6) examples\n",
      "train_size : 800, test_size : 100, val_size : 100\n",
      "8 of 200 classes have atleast try_k_shot + try_n_query (6) examples\n"
     ]
    }
   ],
   "source": [
    "dataset = ShardedEpisodicDataset(data_paths, meta_path, 5, 5, 5, split=\"train\")\n",
    "val_dataset = ShardedEpisodicDataset(data_paths, meta_path, 3, 3, 3, split=\"val\")\n",
    "test_dataset = ShardedEpisodicDataset(data_paths, meta_path, 3, 3, 3, split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(model, lambda_l2=1e-4):\n",
    "    l2_norm = 0\n",
    "    for param in model.parameters():\n",
    "        l2_norm += param.pow(2).sum()\n",
    "    return lambda_l2 * l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    model = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "    self.features = nn.Sequential(\n",
    "      model.conv1,\n",
    "      model.bn1,\n",
    "      model.relu,\n",
    "      model.maxpool,\n",
    "      model.layer1,\n",
    "      model.layer2,\n",
    "      model.layer3,\n",
    "      model.layer4\n",
    "    )  # (B, 512, H/32, W/32)\n",
    "\n",
    "    self.output_channels = 512\n",
    "    self.max_nodes = 132 # 1056/32 * 128 / 32 = 33 * 4 = 132\n",
    "\n",
    "    # Learned positional encoding\n",
    "    self.pos_enc = nn.Parameter(torch.randn(self.max_nodes, self.output_channels))\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.features(x) # (B, 512, H/32, W/32)\n",
    "    x = x.flatten(2).transpose(1, 2)  # (B, W / 32 * H / 32, 512)\n",
    " #   x = x.view(*x.shape[:2], -1).transpose(1, 2) # (B, W / 32 * H / 32, 512)\n",
    "    x = x + self.pos_enc # Add positional encoding\n",
    "    return x # (B, W * H / 1024, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProtoNet stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    # x: [n_sample, n_feature], y: [n_class, n_feature]\n",
    "    x_norm = (x ** 2).sum(dim=1).unsqueeze(1)     # [n_sample, 1]\n",
    "    y_norm = (y ** 2).sum(dim=1).unsqueeze(0)     # [1, n_class]\n",
    "    dist = x_norm + y_norm - 2.0 * x @ y.T        # [n_sample, n_class]\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "  def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "    super().__init__()\n",
    "    self.gamma = gamma\n",
    "    self.alpha = alpha\n",
    "    self.reduction = reduction\n",
    "\n",
    "  def forward(self, logits, targets):\n",
    "    bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "    pt = torch.exp(-bce_loss)\n",
    "    focal_loss = ((1 - pt) ** self.gamma) * bce_loss\n",
    "    if self.alpha is not None:\n",
    "      focal_loss = self.alpha * focal_loss\n",
    "    if self.reduction == 'mean':\n",
    "      return focal_loss.mean()\n",
    "    elif self.reduction == 'sum':\n",
    "      return focal_loss.sum()\n",
    "    else:\n",
    "      return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mAP(y_true, y_scores):\n",
    "  num_classes = y_true.shape[1]\n",
    "  APs = []\n",
    "  for i in range(num_classes):\n",
    "    if np.sum(y_true[:, i]) >0:\n",
    "      AP = average_precision_score(y_true[:, i], y_scores[:, i])\n",
    "      APs.append(AP)\n",
    "  return np.mean(APs) if len(APs) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_embeddings(model, data, batch_size):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        mini_batch = data[i:i+batch_size]\n",
    "        embed = model(mini_batch)\n",
    "        embeddings.append(embed)\n",
    "    return torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prototypical_loss(model, episode, device, use_focal=True, gamma=2.0, alpha=1.0, max_subset_size=3, max_num_subsets=500):\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    \n",
    "    support_label = episode['support_label'].to(device)\n",
    "    query_label = episode['query_label'].to(device)\n",
    "    support_data = episode['support_data'].to(device)\n",
    "    query_data = episode['query_data'].to(device)\n",
    "\n",
    "    def get_power_set(indices, max_len=max_subset_size):\n",
    "        s = list(indices)\n",
    "        return list(chain.from_iterable(combinations(s, r) for r in range(1, min(len(s), max_len) + 1)))\n",
    "\n",
    "    # Gather unique label combinations\n",
    "    unique_combos = set()\n",
    "    for lbl in torch.cat([support_label, query_label], 0):\n",
    "        active = tuple(i for i, v in enumerate(lbl) if v == 1)\n",
    "        if active:\n",
    "            unique_combos.add(active)\n",
    "\n",
    "    all_subsets = set()\n",
    "    for combo in unique_combos:\n",
    "        # only subsets up to max_subset_size\n",
    "        for r in range(1, min(len(combo), max_subset_size)+1):\n",
    "            for sub in combinations(combo, r):\n",
    "                all_subsets.add(tuple(sorted(sub)))\n",
    "\n",
    "    all_subsets = sorted(all_subsets, key=lambda s: (len(s), s))\n",
    "    if len(all_subsets) > max_num_subsets:\n",
    "        all_subsets = all_subsets[:max_num_subsets]\n",
    "\n",
    "    subset_map = {s: i for i, s in enumerate(all_subsets)}\n",
    "\n",
    "    def extend_labels(lbls):\n",
    "        ext = torch.zeros((lbls.size(0), len(subset_map)), device=device)\n",
    "        for i, row in enumerate(lbls):\n",
    "            active = [j for j,v in enumerate(row) if v==1]\n",
    "            for r in range(1, min(len(active), max_subset_size)+1):\n",
    "                for sub in combinations(active, r):\n",
    "                    idx = subset_map.get(tuple(sorted(sub)))\n",
    "                    if idx is not None:\n",
    "                        ext[i, idx] = 1\n",
    "        return ext\n",
    "\n",
    "    support_ext = extend_labels(support_label)\n",
    "    query_ext   = extend_labels(query_label)\n",
    "\n",
    "    # Get embeddings\n",
    "    support_emb = compute_grad_embeddings(model, support_data, batch_size=4)\n",
    "    query_emb   = compute_grad_embeddings(model, query_data, batch_size=4)\n",
    "\n",
    "    # Vectorized prototype averaging\n",
    "    w = support_ext.T  # (num_proto, num_support)\n",
    "    protos = (w @ support_emb) / w.sum(dim=1, keepdim=True).clamp(min=1)\n",
    "\n",
    "    # Compute distances & logits\n",
    "    dists  = torch.cdist(query_emb, protos)\n",
    "    logits = -dists\n",
    "\n",
    "\n",
    "    # Loss\n",
    "    if use_focal:\n",
    "        pos_freq = query_ext.float().mean(0)\n",
    "        eps = 1e-6\n",
    "        raw_w = 1.0 / (pos_freq + eps)\n",
    "        pos_w = torch.clamp(raw_w, max=10.0).to(device)\n",
    "        loss_fn = FocalLoss(gamma=gamma, alpha=pos_w)\n",
    "    else:\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "    loss = loss_fn(logits, query_ext)\n",
    "\n",
    "    # Evaluation metrics\n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(logits)\n",
    "        y_true = query_ext.cpu().numpy()\n",
    "        APs = [average_precision_score(y_true[:, i], probs[:, i].cpu().numpy())\n",
    "               for i in range(len(subset_map)) if y_true[:, i].sum()>0]\n",
    "        mAP = float(np.mean(APs)) if APs else 0.0\n",
    "\n",
    "        y_pred = (probs>0.5).cpu().numpy().astype(int)\n",
    "        f1 = f1_score(y_true.flatten(), y_pred.flatten(), average='macro')\n",
    "\n",
    "    return loss, f1, mAP\n",
    "\n",
    "  # # Apply sigmoid and compute loss using BCE\n",
    "  # #print(distances.shape)\n",
    "  # #print(query_ext_lbls.float().shape)\n",
    "  # pos_freq = query_ext_lbls.float().mean(dim=0)\n",
    "  # epsilon = 1e-6\n",
    "  # raw_pos_weight = 1.0 / (pos_freq + epsilon)\n",
    "  # max_weight = 10.0\n",
    "  # pos_weight  = torch.clamp(raw_pos_weight, max = max_weight)\n",
    "  # loss_fn = nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
    "  # loss = loss_fn(distances, query_ext_lbls.float())\n",
    "\n",
    "  # # compress the extended prediction back to normal\n",
    "  # pred = torch.zeros(episode['query_data'].shape[0], num_classes, dtype=torch.bool, device=device)\n",
    "  # for i in range(episode['query_data'].shape[0]):\n",
    "  #   min_dist = torch.min(distances[i])  # 1. Get smallest distance value for this query\n",
    "  #   candidates = (distances[i] == min_dist).nonzero(as_tuple=True)[0]  # 2. Find ALL prototypes with this distance\n",
    "  #   best_idx = max(candidates, key=lambda idx: len(all_subsets[idx]))  # 3. Select largest subset\n",
    "  #   pred[i, all_subsets[best_idx]] = True\n",
    "\n",
    "  # true_bool = episode['query_label'].to(device).bool()\n",
    "  # tp = (pred & true_bool).sum().float()\n",
    "  # fp = (pred & ~true_bool).sum().float()\n",
    "  # fn = (~pred & true_bool).sum().float()\n",
    "\n",
    "  # precision = tp / (tp + fp + 1e-6)  # Adding small value to avoid division by zero\n",
    "  # recall = tp / (tp + fn + 1e-6)\n",
    "  # f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "\n",
    "  # return loss, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, episode, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    num_classes = episode['support_label'].shape[1]\n",
    "    unique_combinations = set()\n",
    "    for label_set in episode['support_label']:\n",
    "        active = tuple(i for i, val in enumerate(label_set) if val == 1)\n",
    "        if active:\n",
    "            unique_combinations.add(active)\n",
    "    for label_set in episode['query_label']:\n",
    "        active = tuple(i for i, val in enumerate(label_set) if val == 1)\n",
    "        if active:\n",
    "            unique_combinations.add(active)\n",
    "\n",
    "    def get_power_set(indices):\n",
    "        return list(chain.from_iterable(combinations(indices, r) for r in range(1, len(indices) + 1)))\n",
    "\n",
    "    all_subsets = set()\n",
    "    for idx_comb in unique_combinations:\n",
    "        for subset in get_power_set(idx_comb):\n",
    "            all_subsets.add(tuple(sorted(subset)))\n",
    "    all_subsets = sorted(all_subsets, key=lambda s: (len(s), s))\n",
    "    subset_map = {subset: i for i, subset in enumerate(all_subsets)}\n",
    "\n",
    "    def extend_labels(labels):\n",
    "        ext = torch.zeros((len(labels), len(all_subsets)), dtype=torch.float, device=device)\n",
    "        for i, row in enumerate(labels):\n",
    "            active_indices = tuple(sorted(j for j, val in enumerate(row) if val == 1))\n",
    "            if active_indices:\n",
    "                for subset in get_power_set(active_indices):\n",
    "                    subset = tuple(sorted(subset))\n",
    "                    ext[i, subset_map[subset]] = 1.0\n",
    "        return ext\n",
    "\n",
    "    support_ext_lbls = extend_labels(episode['support_label'])\n",
    "    query_ext_lbls = extend_labels(episode['query_label'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        support_embeddings = model(episode['support_data'].to(device))\n",
    "        query_embeddings = model(episode['query_data'].to(device))\n",
    "    d = support_embeddings.shape[1]\n",
    "    num_proto = len(all_subsets)\n",
    "    prototypes = torch.zeros((num_proto, d), device=device)\n",
    "    counts = torch.zeros(num_proto, device=device)\n",
    "    for i in range(support_embeddings.shape[0]):\n",
    "        active_prototypes = support_ext_lbls[i].nonzero(as_tuple=True)[0]\n",
    "        for p in active_prototypes:\n",
    "            prototypes[p] += support_embeddings[i]\n",
    "            counts[p] += 1\n",
    "    counts = counts.clamp(min=1)\n",
    "    prototypes /= counts.unsqueeze(1)\n",
    "\n",
    "    distances = euclidean_dist(query_embeddings, prototypes)\n",
    "    logits = -distances  # Convert distances to logits\n",
    "    probs = torch.sigmoid(logits)\n",
    "    pred = (probs > 0.5).int()\n",
    "\n",
    "    return pred, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAT stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out, num_heads=8, concat_heads=True, alpha=0.3, top_k=5):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.concat_heads = concat_heads\n",
    "        self.top_k = top_k\n",
    "        self.output_project = nn.Linear(c_out * num_heads if self.concat_heads else c_out, c_out)\n",
    "\n",
    "        if self.concat_heads:\n",
    "            assert c_out % num_heads == 0, \"c_out must be divisible by num_heads\"\n",
    "            c_out = c_out // num_heads\n",
    "\n",
    "        self.projection = nn.Linear(c_in, c_out * num_heads)\n",
    "        self.a = nn.Parameter(torch.Tensor(num_heads, 2 * c_out))\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.projection.weight, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a, gain=1.414)\n",
    "\n",
    "    def compute_adj_matrix(self, node_feats, drop_prob=0.2):\n",
    "        # Normalize features along the last dimension (using lowercase 'normalize')\n",
    "        norm_feats = F.normalize(node_feats, p=2, dim=-1)\n",
    "        # Here, node_feats has shape (batch_size, num_nodes, feature_dim).\n",
    "        # We need to compute pairwise similarity per batch.\n",
    "        # Use torch.bmm to perform batched matrix multiplication.\n",
    "        sim = torch.bmm(norm_feats, norm_feats.transpose(1, 2))  # (batch, num_nodes, num_nodes)\n",
    "        # Create a binary adjacency matrix based on a threshold (e.g., 0.5)\n",
    "        if self.top_k is not None:\n",
    "          B, N, _ = sim.shape\n",
    "          topk_values, top_k_indices = torch.topk(sim, k=self.top_k, dim=-1)\n",
    "          mask = torch.zeros_like(sim)\n",
    "          mask.scatter_(2, top_k_indices, 1.0)\n",
    "          sim = sim * mask\n",
    "\n",
    "        adj_matrix = (sim > 0.4).float()\n",
    "\n",
    "        if drop_prob > 0.0:\n",
    "          drop_mask = (torch.rand_like(adj_matrix) > drop_prob).float()\n",
    "          adj_matrix = adj_matrix * drop_mask\n",
    "\n",
    "        return adj_matrix\n",
    "\n",
    "    def forward(self, node_feats, print_attn_probs=False):\n",
    "        batch_size, num_nodes, _ = node_feats.shape\n",
    "\n",
    "        # Compute the adjacency matrix from node features.\n",
    "        adj_matrix = self.compute_adj_matrix(node_feats, drop_prob=0.2)  # Expected shape: (batch_size, num_nodes, num_nodes)\n",
    "\n",
    "        projected_feats = self.projection(node_feats)  # (B, N, heads * d_head)\n",
    "        residual = projected_feats.clone()\n",
    "        node_feats = projected_feats.view(batch_size, num_nodes, self.num_heads, -1)\n",
    "\n",
    "        # Now, get the indices of nonzero elements in the adj matrix.\n",
    "        # Note: For a batched adj_matrix, nonzero() returns indices with shape (num_edges, 3)\n",
    "        # edges[:, 0] is the batch index, edges[:, 1] is the row index, and edges[:, 2] is the column index.\n",
    "        edges = (adj_matrix > 0.0).nonzero(as_tuple=False)\n",
    "        batch_indices = edges[:, 0]\n",
    "        offset = batch_indices * num_nodes\n",
    "        edges_indices_row = offset + edges[:, 1]\n",
    "        edges_indices_col = offset + edges[:, 2]\n",
    "\n",
    "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, -1)\n",
    "\n",
    "        a_input = torch.cat([\n",
    "            torch.index_select(node_feats_flat, dim=0, index=edges_indices_row),\n",
    "            torch.index_select(node_feats_flat, dim=0, index=edges_indices_col)\n",
    "        ], dim=-1)\n",
    "\n",
    "        attn_logits = torch.einsum('bhc,hc->bh', a_input, self.a)\n",
    "        attn_logits = self.leakyrelu(attn_logits)\n",
    "\n",
    "\n",
    "        # Create an attention matrix with shape (batch_size, num_nodes, num_nodes, num_heads)\n",
    "        attn_matrix = torch.full((*adj_matrix.shape, self.num_heads), -1e9, device=node_feats.device)\n",
    "        # Assign computed logits to positions where adj_matrix is 1.\n",
    "        # We expand adj_matrix to have a head dimension.\n",
    "        attn_matrix[(adj_matrix > 0.0).unsqueeze(-1).expand(-1, -1, -1, self.num_heads)] = attn_logits.reshape(-1)\n",
    "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
    "\n",
    "        if print_attn_probs:\n",
    "            print(\"attention probs \\n\", attn_probs.permute(0, 3, 1, 2).detach().cpu())\n",
    "\n",
    "        node_feats = torch.einsum('bijh,bjhc->bihc', attn_probs, node_feats)\n",
    "\n",
    "        if self.concat_heads:\n",
    "            node_feats = node_feats.reshape(batch_size, num_nodes, -1)\n",
    "        else:\n",
    "            node_feats = node_feats.mean(dim=2)\n",
    "\n",
    "        if node_feats.shape == residual.shape:\n",
    "            node_feats = node_feats + residual\n",
    "\n",
    "        node_feats = self.output_project(node_feats)\n",
    "\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnGat(nn.Module):\n",
    "  def __init__(self, cnn_encoder, gat_layer, embed_size, device, cnn_embed_size=512):\n",
    "    super().__init__()\n",
    "    self.device = device\n",
    "    self.embed_size = embed_size\n",
    "    self.cnn_encoder = cnn_encoder()\n",
    "    self.gat_layer = gat_layer(\n",
    "      c_in=cnn_embed_size,\n",
    "      c_out=self.embed_size // 49, # there are 7x7 nodes from the cnn, so we calc how many features each node can have to have embed_size size when flattened\n",
    "    )\n",
    "    self.norma = nn.LayerNorm(self.embed_size)\n",
    "    self.cnn_encoder.to(device)\n",
    "    self.gat_layer.to(device)\n",
    "\n",
    "  def forward(self, data):\n",
    "    small_batch_size = 4  # You can tune this for Colab/VRAM\n",
    "    B = data.size(0)\n",
    "    cnn_outputs = []\n",
    "\n",
    "    # Manually batch over input to avoid VRAM spikes\n",
    "    for i in range(0, B, small_batch_size):\n",
    "        mini_data = data[i:i + small_batch_size].to(self.device)  # (miniB, 1, H, W)\n",
    "        with torch.no_grad():  # Optional: skip gradients in feature extractor\n",
    "            mini_output = self.cnn_encoder(mini_data)  # → (miniB, C, H, W)\n",
    "        cnn_outputs.append(mini_output)\n",
    "\n",
    "    # Concatenate batched outputs\n",
    "    cnn_embeds = torch.cat(cnn_outputs, dim=0)  # (B, C, H, W)\n",
    "    _, C, H, W = cnn_embeds.shape\n",
    "\n",
    "    # Reshape for GAT: (B, C, H, W) → (B, H*W, C)\n",
    "    nodes = cnn_embeds.permute(0, 2, 3, 1).reshape(B, H * W, C)\n",
    "\n",
    "    # GAT layer processes spatial tokens\n",
    "    nodes = self.gat_layer(nodes)  # (B, H*W, embed_per_node)\n",
    "\n",
    "    # Flatten to (B, total_embed_size)\n",
    "    gat_embeds = nodes.view(nodes.size(0), -1)\n",
    "\n",
    "    return gat_embeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import random\n",
    "def check_val(model, num_checks=10):\n",
    "    running_f1 = 0.0\n",
    "    min_f1 = float('inf')\n",
    "    max_f1 = float('-inf')\n",
    "    running_map = 0.0\n",
    "    for i in range(num_checks):\n",
    "        test_ep = val_dataset[0]\n",
    "        _, f1, mAP = prototypical_loss(model, test_ep, device, use_focal=True, gamma=2.0, alpha=1.0)\n",
    "        f1_val = f1.item() if torch.is_tensor(f1) else f1\n",
    "        running_f1 += f1_val\n",
    "        running_map += mAP\n",
    "        min_f1 = min(min_f1, f1_val)\n",
    "        max_f1 = max(max_f1, f1_val)\n",
    "\n",
    "    avg_f1 = running_f1 / num_checks\n",
    "    avg_map = running_map / num_checks\n",
    "    print(f\"Val: Avg F1: {avg_f1:.2f}, min: {min_f1:.2f}, max: {max_f1:.2f}, Avg mAP: {avg_map:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, optimizer, batch_size, epochs, device):\n",
    "  model.train()\n",
    "  model.to(device)\n",
    "\n",
    "  random.seed(42)\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    running_f1 = 0.0\n",
    "    running_mAP = 0.0\n",
    "    for batch in tqdm(range(batch_size)):\n",
    "      optimizer.zero_grad()\n",
    "      episode = dataset[0] # the indexing on our custom dataset is nonsense on purpose, every index gives random result each time\n",
    "\n",
    "      loss, f1, mAP = prototypical_loss(model, episode, device, use_focal=True, gamma=2.0, alpha=1.0)\n",
    "      loss += l2_regularization(model, lambda_l2=1e-4)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item()\n",
    "      running_f1 += f1.item()\n",
    "      running_mAP += mAP.item()\n",
    "\n",
    "      del episode, loss, f1\n",
    "      gc.collect()\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss = running_loss / batch_size\n",
    "    epoch_f1 = running_f1 / batch_size\n",
    "    epoch_mAP = running_mAP / batch_size\n",
    "    print(f'Epoch {epoch+1} Complete - Loss: {epoch_loss:.4f} F1: {epoch_f1:.2f} mAP: {epoch_mAP:.2f}')\n",
    "    check_val(model)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aniru\\.conda\\envs\\pytorch-env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c194dbb0587e4268ad8279b8eb6a0cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Complete - Loss: 4502.7261 F1: 0.00 mAP: 0.05\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89206f00fd54fdfa02c7b91555095d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Complete - Loss: 3707.6733 F1: 0.00 mAP: 0.06\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa147cb6f14f426ba1ab77a91c0a6450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Complete - Loss: 1662.2552 F1: 0.00 mAP: 0.09\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f9f70262ea42e7b134d46832b216d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Complete - Loss: 3071.6277 F1: 0.00 mAP: 0.08\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd18a372de194cf8b05b6d99601df744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Complete - Loss: 1270.9792 F1: 0.00 mAP: 0.07\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f67db352224349a6590063b9a4d74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Complete - Loss: 1546.6217 F1: 0.00 mAP: 0.09\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbb7fc54e7f4c9dadb82644a22c2e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Complete - Loss: 735.5558 F1: 0.00 mAP: 0.06\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5285816ca6b1480591fe60ddc6862ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Complete - Loss: 418.1100 F1: 0.00 mAP: 0.07\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856c1838f4d24c6b82e676a39a51e6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Complete - Loss: 584.7097 F1: 0.00 mAP: 0.09\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848cc57c21884c2095df722cc4e25f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Complete - Loss: 377.0464 F1: 0.00 mAP: 0.07\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70980e26c82a4aa4af6d01aa95bc9ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Complete - Loss: 257.7603 F1: 0.00 mAP: 0.10\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab62837f73d4f299787d5a2971a9dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Complete - Loss: 716.4217 F1: 0.00 mAP: 0.10\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e941a437a3764f67a0afb9dafc2d3451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Complete - Loss: 325.2314 F1: 0.00 mAP: 0.27\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92198dbf71864889bf3cda90d8b09a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Complete - Loss: 483.9039 F1: 0.00 mAP: 0.13\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31f963f78b0422fb6ee159d348e89e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Complete - Loss: 171.1426 F1: 0.00 mAP: 0.05\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde153989d254e929716f256711f13e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Complete - Loss: 361.3249 F1: 0.00 mAP: 0.25\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02360a7872a142b0a72553a4a6496506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Complete - Loss: 179.9952 F1: 0.00 mAP: 0.16\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87190cfd00ba48589e162833b799cb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Complete - Loss: 87.4403 F1: 0.00 mAP: 0.16\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f134a64396374920905b5dbc007829f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Complete - Loss: 185.4249 F1: 0.00 mAP: 0.17\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1f553d9e944f6f9d05eb3334b77f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Complete - Loss: 196.8330 F1: 0.00 mAP: 0.48\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0344ffdaa42c4610bf0805299f739df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Complete - Loss: 230.9429 F1: 0.00 mAP: 0.20\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed61eeabc02c4f409b1353b2891da8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Complete - Loss: 183.2174 F1: 0.00 mAP: 0.22\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97e2c95d38d4bb089b953db94694b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Complete - Loss: 86.4002 F1: 0.00 mAP: 0.39\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100823b4f4b549e182df74ebf4e04b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Complete - Loss: 145.1480 F1: 0.00 mAP: 0.37\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc12f8abf0954d908d2e46b69db1148e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Complete - Loss: 101.4964 F1: 0.00 mAP: 0.26\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d92f36f8a74bf5a832540492102d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Complete - Loss: 88.2247 F1: 0.00 mAP: 0.30\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1b35b0357945cbaf90ea6cd3caebe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Complete - Loss: 55.5996 F1: 0.00 mAP: 0.69\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac29f878f1f046f4bc1f6587165b32e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Complete - Loss: 95.7957 F1: 0.00 mAP: 0.38\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b63fc377674968abaa9acbc35a6304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Complete - Loss: 93.7661 F1: 0.00 mAP: 0.15\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d468f7ac998b4f8086d72d05788fbead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Complete - Loss: 129.3657 F1: 0.00 mAP: 0.46\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3aca8288994b28a60f040834b7559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Complete - Loss: 90.3758 F1: 0.00 mAP: 0.26\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9b9fd3304c41a49f49dbed04beec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Complete - Loss: 60.5017 F1: 0.00 mAP: 0.30\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9973c211a9d742848c186896fcb6d01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Complete - Loss: 41.7539 F1: 0.00 mAP: 0.61\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c6184b8a0f40d3a1ea0a39d68c079d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Complete - Loss: 49.8972 F1: 0.00 mAP: 0.42\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe07eb24a6464944a94662b5fd30f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Complete - Loss: 49.9561 F1: 0.00 mAP: 0.46\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df2926212fe433aa94a5eca1cefe1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Complete - Loss: 71.9424 F1: 0.00 mAP: 0.39\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e964a17c0b6422a83eac171d6ae9e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Complete - Loss: 45.9229 F1: 0.00 mAP: 0.60\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e69a78bfa3481c9fb00a40ed526084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Complete - Loss: 51.7622 F1: 0.00 mAP: 0.38\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d959012992a84932b61e7ad1f9868e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Complete - Loss: 89.0727 F1: 0.00 mAP: 0.47\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a7e5133cd8441f96c078c2789b5235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Complete - Loss: 95.4495 F1: 0.00 mAP: 0.66\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb55df61cf934676a98441e2c55431ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Complete - Loss: 59.9724 F1: 0.00 mAP: 0.67\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345ca2cf74804d3aaa62eb8bd37a77f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Complete - Loss: 61.2763 F1: 0.00 mAP: 0.64\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2926ffb61748d3837febc8c4a22b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Complete - Loss: 64.1643 F1: 0.00 mAP: 0.32\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9385bbc186849eaa3051ddb4cffbfbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Complete - Loss: 51.6828 F1: 0.00 mAP: 0.46\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5236835480b04b5ca2252c6f194e9409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Complete - Loss: 57.7208 F1: 0.00 mAP: 0.57\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f07a56b8cc4df4afb370b0fdcc3147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Complete - Loss: 45.3970 F1: 0.00 mAP: 0.53\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707b94003e094537a48ca2830a10d04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Complete - Loss: 52.3434 F1: 0.00 mAP: 0.59\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675dfd702c544ac0bc976aa33e25d03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Complete - Loss: 36.1054 F1: 0.00 mAP: 0.49\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db59672c9b974929878fc6de3cd240a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Complete - Loss: 33.8246 F1: 0.00 mAP: 0.62\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d481f2d6f91a44c3b7e442c94ffd6387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Complete - Loss: 40.6560 F1: 0.00 mAP: 0.70\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.41\n"
     ]
    }
   ],
   "source": [
    "model = CnnGat(ConvEncoder, GATLayer, embed_size=6272, device=device)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 3e-4, weight_decay=1e-4)\n",
    "\n",
    "train(model, dataset, optimizer, batch_size=1, epochs=10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Temp\\ipykernel_9252\\1519225210.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  shard = torch.load(shard_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 3, 224, 224]), torch.Size([9, 200]), torch.Size([9, 3, 224, 224]), torch.Size([9, 200])\n"
     ]
    }
   ],
   "source": [
    "test_episode = test_dataset[0]\n",
    "\n",
    "support_data = test_episode['support_data']\n",
    "support_label = test_episode['support_label']\n",
    "query_data = test_episode['query_data']\n",
    "query_label = test_episode['query_label']\n",
    "\n",
    "# print shape for debugging\n",
    "print(f\"{test_episode['support_data'].shape}, {test_episode['support_label'].shape}, {test_episode['query_data'].shape}, {test_episode['query_label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Tensor.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get prediction and performance\u001b[39;00m\n\u001b[0;32m      2\u001b[0m pred, f1 \u001b[38;5;241m=\u001b[39m predict(model, test_episode, device)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1 of test episode \u001b[39m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mf1\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.2f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aniru\\.conda\\envs\\pytorch-env\\Lib\\site-packages\\torch\\_tensor.py:1053\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[1;34m(self, format_spec)\u001b[0m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[1;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__format__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_spec\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
     ]
    }
   ],
   "source": [
    "# get prediction and performance\n",
    "pred, f1 = predict(model, test_episode, device)\n",
    "print(f\"f1 of test episode {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for visualization\n",
    "imgs = test_episode['query_data'].cpu().numpy().transpose(0, 2, 3, 1)\n",
    "col_names = ['Accelerating_and_revving_and_vroom', 'Accordion', 'Acoustic_guitar', 'Aircraft', 'Alarm', 'Animal', 'Applause', 'Bark', 'Bass_drum', 'Bass_guitar', 'Bathtub_(filling_or_washing)', 'Bell', 'Bicycle', 'Bicycle_bell', 'Bird', 'Bird_vocalization_and_bird_call_and_bird_song', 'Boat_and_Water_vehicle', 'Boiling', 'Boom', 'Bowed_string_instrument', 'Brass_instrument', 'Breathing', 'Burping_and_eructation', 'Bus', 'Buzz', 'Camera', 'Car', 'Car_passing_by', 'Cat', 'Chatter', 'Cheering', 'Chewing_and_mastication', 'Chicken_and_rooster', 'Child_speech_and_kid_speaking', 'Chime', 'Chink_and_clink', 'Chirp_and_tweet', 'Chuckle_and_chortle', 'Church_bell', 'Clapping', 'Clock', 'Coin_(dropping)', 'Computer_keyboard', 'Conversation', 'Cough', 'Cowbell', 'Crack', 'Crackle', 'Crash_cymbal', 'Cricket', 'Crow', 'Crowd', 'Crumpling_and_crinkling', 'Crushing', 'Crying_and_sobbing', 'Cupboard_open_or_close', 'Cutlery_and_silverware', 'Cymbal', 'Dishes_and_pots_and_pans', 'Dog', 'Domestic_animals_and_pets', 'Domestic_sounds_and_home_sounds', 'Door', 'Doorbell', 'Drawer_open_or_close', 'Drill', 'Drip', 'Drum', 'Drum_kit', 'Electric_guitar', 'Engine', 'Engine_starting', 'Explosion', 'Fart', 'Female_singing', 'Female_speech_and_woman_speaking', 'Fill_(with_liquid)', 'Finger_snapping', 'Fire', 'Fireworks', 'Fixed-wing_aircraft_and_airplane', 'Fowl', 'Frog', 'Frying_(food)', 'Gasp', 'Giggle', 'Glass', 'Glockenspiel', 'Gong', 'Growling', 'Guitar', 'Gull_and_seagull', 'Gunshot_and_gunfire', 'Gurgling', 'Hammer', 'Hands', 'Harmonica', 'Harp', 'Hi-hat', 'Hiss', 'Human_group_actions', 'Human_voice', 'Idling', 'Insect', 'Keyboard_(musical)', 'Keys_jangling', 'Knock', 'Laughter', 'Liquid', 'Livestock_and_farm_animals_and_working_animals', 'Male_singing', 'Male_speech_and_man_speaking', 'Mallet_percussion', 'Marimba_and_xylophone', 'Mechanical_fan', 'Mechanisms', 'Meow', 'Microwave_oven', 'Motor_vehicle_(road)', 'Motorcycle', 'Music', 'Musical_instrument', 'Ocean', 'Organ', 'Packing_tape_and_duct_tape', 'Percussion', 'Piano', 'Plucked_string_instrument', 'Pour', 'Power_tool', 'Printer', 'Purr', 'Race_car_and_auto_racing', 'Rail_transport', 'Rain', 'Raindrop', 'Ratchet_and_pawl', 'Rattle', 'Rattle_(instrument)', 'Respiratory_sounds', 'Ringtone', 'Run', 'Sawing', 'Scissors', 'Scratching_(performance_technique)', 'Screaming', 'Screech', 'Shatter', 'Shout', 'Sigh', 'Singing', 'Sink_(filling_or_washing)', 'Siren', 'Skateboard', 'Slam', 'Sliding_door', 'Snare_drum', 'Sneeze', 'Speech', 'Speech_synthesizer', 'Splash_and_splatter', 'Squeak', 'Stream', 'Strum', 'Subway_and_metro_and_underground', 'Tabla', 'Tambourine', 'Tap', 'Tearing', 'Telephone', 'Thump_and_thud', 'Thunder', 'Thunderstorm', 'Tick', 'Tick-tock', 'Toilet_flush', 'Tools', 'Traffic_noise_and_roadway_noise', 'Train', 'Trickle_and_dribble', 'Truck', 'Trumpet', 'Typewriter', 'Typing', 'Vehicle', 'Vehicle_horn_and_car_horn_and_honking', 'Walk_and_footsteps', 'Water', 'Water_tap_and_faucet', 'Waves_and_surf', 'Whispering', 'Whoosh_and_swoosh_and_swish', 'Wild_animals', 'Wind', 'Wind_chime', 'Wind_instrument_and_woodwind_instrument', 'Wood', 'Writing', 'Yell', 'Zipper_(clothing)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare grid\n",
    "grid_size = int(np.ceil(np.sqrt(imgs.shape[0])))\n",
    "fig, axes = plt.subplots(grid_size, grid_size, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(imgs.shape[0]):\n",
    "    ax = axes[i]\n",
    "    img = imgs[i]\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    active_indices = torch.nonzero(pred[i], as_tuple=True)[0]\n",
    "    selected_labels = [col_names[i] for i in active_indices]\n",
    "\n",
    "    # get query labels\n",
    "    query_labels = torch.nonzero(test_episode['query_label'][i], as_tuple=True)[0]\n",
    "    query_label_names = [col_names[i] for i in query_labels]\n",
    "\n",
    "    ax.set_title(f\"Pred: {', '.join(selected_labels)}\\nTrue: {', '.join(query_label_names)}\", fontsize=7)\n",
    "\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get avg f1 in test set\n",
    "\n",
    "checks = 200\n",
    "running_f1 = 0.0\n",
    "min_f1 = 2.0\n",
    "max_f1 = -1.0\n",
    "for i in tqdm(range(checks)):\n",
    "  test_ep = test_dataset.getEpisode(6, 6, 6)\n",
    "  _, f1 = predict(model, test_ep, device)\n",
    "  min_f1 = min(min_f1, f1)\n",
    "  max_f1 = max(max_f1, f1)\n",
    "  running_f1 += f1\n",
    "\n",
    "running_f1 = running_f1 / checks\n",
    "print(f\"Avg f1 in test set {running_f1:.2f}, min: {min_f1:.2f}, max: {max_f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
