{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import random\n",
    "from itertools import chain, combinations\n",
    "from sklearn.metrics import f1_score, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "import threading\n",
    "from multiprocessing import Manager\n",
    "import gc\n",
    "\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "#device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing our spectrogram using imagenet stats\n",
    "mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling frequency and time masking to spectrograms\n",
    "\n",
    "class SpecAugment:\n",
    "    \"\"\"Applies frequency and time masking to spectrograms\"\"\"\n",
    "    def __init__(self, freq_mask_max=0.15, time_mask_max=0.20):\n",
    "        self.freq_mask_max = freq_mask_max\n",
    "        self.time_mask_max = time_mask_max\n",
    "    \n",
    "    def __call__(self, spec):\n",
    "        spec = spec.clone()\n",
    "        n_mels, n_time = spec.shape\n",
    "        \n",
    "        # Frequency masking\n",
    "        if self.freq_mask_max > 0:\n",
    "            max_freq_bands = int(n_mels * self.freq_mask_max)\n",
    "            freq_bands = random.randint(1, max_freq_bands)\n",
    "            freq_start = random.randint(0, n_mels - freq_bands)\n",
    "            spec[freq_start:freq_start+freq_bands, :] = spec.min()\n",
    "        \n",
    "        # Time masking\n",
    "        if self.time_mask_max > 0:\n",
    "            max_time_steps = int(n_time * self.time_mask_max)\n",
    "            time_steps = random.randint(1, max_time_steps)\n",
    "            time_start = random.randint(0, n_time - time_steps)\n",
    "            spec[:, time_start:time_start+time_steps] = spec.min()\n",
    "        \n",
    "        return spec\n",
    "    \n",
    "# It Mixes two audio samples with adjustable ratio\n",
    "\n",
    "class AudioMixer:\n",
    "    \n",
    "    def __init__(self, alpha=0.5, mix_prob=0.5, min_mix_ratio=0.3):\n",
    "        self.alpha = alpha\n",
    "        self.mix_prob = mix_prob\n",
    "        self.min_mix_ratio = min_mix_ratio\n",
    "\n",
    "    def __call__(self, spec1, label1, specsList, labelsList):\n",
    "        if random.random() > self.mix_prob:\n",
    "            return spec1, label1\n",
    "        idx2 = random.randint(0, specsList.shape[0] - 1)\n",
    "        spec2 = specsList[idx2]\n",
    "        label2 = labelsList[idx2]\n",
    "        if spec1.shape != spec2.shape:\n",
    "            raise ValueError(\"Spectrograms is somehow not in same shape\")\n",
    "        lam = np.random.beta(self.alpha, self.alpha)\n",
    "        lam = lam * 1.0 * (1.0 - 2 * self.min_mix_ratio) + self.min_mix_ratio\n",
    "        mixed_spec = lam * spec1 + (1 - lam) * spec2\n",
    "        mixed_label = torch.clamp(label1 + label2, 0, 1)\n",
    "        return mixed_spec, mixed_label\n",
    "    \n",
    "spec_augment = SpecAugment()\n",
    "audio_mixer = AudioMixer()\n",
    "\n",
    "def batch_augment(specsList, labelsList):\n",
    "    augmented_specs = []\n",
    "    augmented_labels = []\n",
    "    N = specsList.shape[0]\n",
    "    for i in range(N):\n",
    "        spec = specsList[i]\n",
    "        label = labelsList[i]\n",
    "        spec, label = audio_mixer(spec, label, specsList, labelsList)\n",
    "        spec = spec_augment(spec)\n",
    "        augmented_specs.append(spec)\n",
    "        augmented_labels.append(label)\n",
    "    augmented_specs = torch.stack(augmented_specs)\n",
    "    augmented_labels = torch.stack(augmented_labels)\n",
    "    augmented_specs = augmented_specs.unsqueeze(1).expand(-1, 3, -1, -1)\n",
    "    augmented_specs = (augmented_specs - mean) / std\n",
    "    return augmented_specs, augmented_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShardedEpisodicDataset():\n",
    "    def __init__(self, data_paths, meta_path, min_n_way, try_k_shot, try_n_query, split=\"train\",\n",
    "                 test_split=0.2, val_split=0.2, split_seed=33, min_examples_per_class=15):\n",
    "        self.data_paths = data_paths\n",
    "        self.min_n_way = min_n_way\n",
    "        self.try_k_shot = try_k_shot\n",
    "        self.try_n_query = try_n_query\n",
    "\n",
    "        # load metadata\n",
    "        meta = torch.load(meta_path)\n",
    "        self.rel_idxs = meta['rel_idxs']\n",
    "        self.n_examples = self.rel_idxs[-1] + 1\n",
    "        meta_class_idxs = meta['class_idxs']\n",
    "        self.n_classes = len(meta_class_idxs)\n",
    "\n",
    "        # Get all class indices\n",
    "        all_class_idxs = [[i.item() for i in meta_class_idxs[c]] for c in range(self.n_classes)]\n",
    "\n",
    "        # Filter classes with sufficient examples\n",
    "        valid_classes_for_split = []\n",
    "        for c in range(self.n_classes):\n",
    "            if len(all_class_idxs[c]) >= min_examples_per_class:\n",
    "                valid_classes_for_split.append(c)\n",
    "\n",
    "        print(f\"Classes with >= {min_examples_per_class} examples: {len(valid_classes_for_split)}/{self.n_classes}\")\n",
    "\n",
    "        # CORRECTED: Split SAMPLES within each class, not classes themselves\n",
    "        # All splits see all classes, but with different samples\n",
    "        self.class_idxs = [[] for _ in range(self.n_classes)]\n",
    "\n",
    "        np.random.seed(split_seed)\n",
    "\n",
    "        for c in valid_classes_for_split:\n",
    "            class_samples = all_class_idxs[c]\n",
    "\n",
    "            if len(class_samples) < min_examples_per_class:\n",
    "                continue\n",
    "\n",
    "            # Shuffle samples within this class\n",
    "            shuffled_samples = np.random.permutation(class_samples)\n",
    "\n",
    "            # Split samples within this class\n",
    "            n_test = max(1, int(len(shuffled_samples) * test_split))\n",
    "            n_val = max(1, int(len(shuffled_samples) * val_split))\n",
    "            n_train = len(shuffled_samples) - n_test - n_val\n",
    "\n",
    "            # Ensure we have enough samples for episodes\n",
    "            min_needed = self.try_k_shot + self.try_n_query\n",
    "            if n_train < min_needed or n_val < min_needed or n_test < min_needed:\n",
    "                # If not enough samples, give more to each split\n",
    "                samples_per_split = len(shuffled_samples) // 3\n",
    "                if samples_per_split < min_needed:\n",
    "                    # Use all samples for all splits (with overlap) if really limited\n",
    "                    train_samples = shuffled_samples.tolist()\n",
    "                    val_samples = shuffled_samples.tolist()\n",
    "                    test_samples = shuffled_samples.tolist()\n",
    "                else:\n",
    "                    train_samples = shuffled_samples[:samples_per_split].tolist()\n",
    "                    val_samples = shuffled_samples[samples_per_split:2*samples_per_split].tolist()\n",
    "                    test_samples = shuffled_samples[2*samples_per_split:].tolist()\n",
    "            else:\n",
    "                train_samples = shuffled_samples[:n_train].tolist()\n",
    "                val_samples = shuffled_samples[n_train:n_train+n_val].tolist()\n",
    "                test_samples = shuffled_samples[n_train+n_val:].tolist()\n",
    "\n",
    "            # Assign samples based on split\n",
    "            if split == \"train\":\n",
    "                self.class_idxs[c] = train_samples\n",
    "            elif split == \"val\":\n",
    "                self.class_idxs[c] = val_samples\n",
    "            elif split == \"test\":\n",
    "                self.class_idxs[c] = test_samples\n",
    "            else:\n",
    "                raise ValueError(\"Split must be 'train', 'val', or 'test'\")\n",
    "\n",
    "        # Valid classes for episodes\n",
    "        self.valid_classes = [\n",
    "            c for c, indices in enumerate(self.class_idxs)\n",
    "            if len(indices) >= self.try_k_shot + self.try_n_query\n",
    "        ]\n",
    "\n",
    "        print(f\"{len(self.valid_classes)} classes available for {split} episodes\")\n",
    "\n",
    "        if len(self.valid_classes) < self.min_n_way:\n",
    "            raise ValueError(f\"Not enough valid classes for {split}. Need {self.min_n_way}, have {len(self.valid_classes)}\")\n",
    "\n",
    "        # cache management\n",
    "        self.cache_size = 1\n",
    "        self.manager = Manager()\n",
    "        self.cache = self.manager.dict()\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def _get_idxs(self, idx):\n",
    "        # binary search on shard to find shard\n",
    "        low, high = 0, len(self.rel_idxs) - 1\n",
    "        while (low < high):\n",
    "            mid = (low + high) // 2\n",
    "            if self.rel_idxs[mid] < idx:\n",
    "                low = mid + 1\n",
    "            else:\n",
    "                high = mid\n",
    "        shard_idx = low\n",
    "\n",
    "        if (shard_idx == 0):\n",
    "            abs_idx = idx\n",
    "        else:\n",
    "            abs_idx = idx - self.rel_idxs[shard_idx - 1] - 1\n",
    "        return shard_idx, abs_idx\n",
    "\n",
    "    def _load_shard(self, shard_idx):\n",
    "        shard_path = self.data_paths[shard_idx]\n",
    "\n",
    "        with self.lock:\n",
    "            # Check if shard is already in cache\n",
    "            if shard_path in self.cache:\n",
    "                return self.cache[shard_path]\n",
    "\n",
    "            # If cache is full, remove one item\n",
    "            if len(self.cache) >= self.cache_size:\n",
    "                # More predictable eviction strategy\n",
    "                oldest_key = next(iter(self.cache))\n",
    "                self.cache.pop(oldest_key)\n",
    "\n",
    "            # Load the shard and store in cache\n",
    "            shard = torch.load(shard_path)\n",
    "            self.cache[shard_path] = shard\n",
    "\n",
    "        return shard\n",
    "\n",
    "    def getEpisode(self, n_way, k_shot, n_query):\n",
    "        # Filter classes that have enough examples for this episode\n",
    "        episode_valid_classes = [\n",
    "            c for c in self.valid_classes\n",
    "            if len(self.class_idxs[c]) >= k_shot + n_query\n",
    "        ]\n",
    "\n",
    "        if len(episode_valid_classes) < n_way:\n",
    "            raise ValueError(f\"Not enough classes with {k_shot + n_query} examples. \"\n",
    "                            f\"Need {n_way} classes but only {len(episode_valid_classes)} available.\")\n",
    "\n",
    "        # Choose random subset of n_way classes\n",
    "        selected_classes = random.sample(episode_valid_classes, n_way)\n",
    "\n",
    "        support_indices, query_indices = [], []\n",
    "\n",
    "        for c in selected_classes:\n",
    "            indices = self.class_idxs[c]\n",
    "            if not indices:\n",
    "                continue\n",
    "            selected_indices = random.sample(indices, k_shot + n_query)\n",
    "            support_indices.extend(selected_indices[:k_shot])\n",
    "            query_indices.extend(selected_indices[k_shot:])\n",
    "\n",
    "        support_indices = torch.tensor(support_indices, dtype=torch.long)\n",
    "        query_indices = torch.tensor(query_indices, dtype=torch.long)\n",
    "\n",
    "        unique_shards = set(self._get_idxs(i)[0] for i in support_indices.tolist() + query_indices.tolist())\n",
    "        shard_data = {shard_idx: self._load_shard(shard_idx) for shard_idx in unique_shards}\n",
    "\n",
    "        # Fetch data/labels from those shards\n",
    "        support_data = torch.cat([shard_data[self._get_idxs(i)[0]]['imgs'][self._get_idxs(i)[1]].unsqueeze(0) for i in support_indices])\n",
    "        support_label = torch.cat([shard_data[self._get_idxs(i)[0]]['lbls'][self._get_idxs(i)[1]].unsqueeze(0) for i in support_indices])\n",
    "        query_data = torch.cat([shard_data[self._get_idxs(i)[0]]['imgs'][self._get_idxs(i)[1]].unsqueeze(0) for i in query_indices])\n",
    "        query_label = torch.cat([shard_data[self._get_idxs(i)[0]]['lbls'][self._get_idxs(i)[1]].unsqueeze(0) for i in query_indices])\n",
    "\n",
    "        support_data, support_label = batch_augment(support_data, support_label)\n",
    "        query_data, query_label = batch_augment(query_data, query_label)\n",
    "\n",
    "        return {\n",
    "            'support_data': support_data,\n",
    "            'support_label': support_label,\n",
    "            'query_data': query_data,\n",
    "            'query_label': query_label\n",
    "        }\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Choose random subset of n_way classes\n",
    "        selected_classes = random.sample(self.valid_classes, self.min_n_way)\n",
    "\n",
    "        support_indices, query_indices = [], []\n",
    "\n",
    "        for c in selected_classes:\n",
    "            indices = self.class_idxs[c]\n",
    "            if not indices:\n",
    "                continue\n",
    "            selected_indices = random.sample(indices, self.try_k_shot + self.try_n_query)\n",
    "            support_indices.extend(selected_indices[:self.try_k_shot])\n",
    "            query_indices.extend(selected_indices[self.try_k_shot:])\n",
    "\n",
    "        support_indices = torch.tensor(support_indices, dtype=torch.long)\n",
    "        query_indices = torch.tensor(query_indices, dtype=torch.long)\n",
    "\n",
    "        unique_shards = set(self._get_idxs(i)[0] for i in support_indices.tolist() + query_indices.tolist())\n",
    "        shard_data = {shard_idx: self._load_shard(shard_idx) for shard_idx in unique_shards}\n",
    "\n",
    "        # Fetch data/labels from those shards\n",
    "        support_data = torch.cat([shard_data[self._get_idxs(i)[0]]['imgs'][self._get_idxs(i)[1]].unsqueeze(0) for i in support_indices])\n",
    "        support_label = torch.cat([shard_data[self._get_idxs(i)[0]]['lbls'][self._get_idxs(i)[1]].unsqueeze(0) for i in support_indices])\n",
    "        query_data = torch.cat([shard_data[self._get_idxs(i)[0]]['imgs'][self._get_idxs(i)[1]].unsqueeze(0) for i in query_indices])\n",
    "        query_label = torch.cat([shard_data[self._get_idxs(i)[0]]['lbls'][self._get_idxs(i)[1]].unsqueeze(0) for i in query_indices])\n",
    "\n",
    "        support_data, support_label = batch_augment(support_data, support_label)\n",
    "        query_data, query_label = batch_augment(query_data, query_label)\n",
    "\n",
    "        return {\n",
    "            'support_data': support_data,\n",
    "            'support_label': support_label,\n",
    "            'query_data': query_data,\n",
    "            'query_label': query_label\n",
    "        }\n",
    "\n",
    "    def get_split_info(self):\n",
    "        \"\"\"Get information about the current split\"\"\"\n",
    "        total_samples = sum(len(indices) for indices in self.class_idxs if indices)\n",
    "        samples_per_class = [len(indices) for indices in self.class_idxs if indices]\n",
    "\n",
    "        return {\n",
    "            'total_samples': total_samples,\n",
    "            'valid_classes': len(self.valid_classes),\n",
    "            'avg_samples_per_class': np.mean(samples_per_class) if samples_per_class else 0,\n",
    "            'min_samples_per_class': np.min(samples_per_class) if samples_per_class else 0,\n",
    "            'max_samples_per_class': np.max(samples_per_class) if samples_per_class else 0\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Temp\\ipykernel_9252\\1539366073.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta = torch.load(meta_path)\n"
     ]
    }
   ],
   "source": [
    "all_pths = list(Path(\"/content\").glob(\"*.pth\"))\n",
    "all_pths.sort()\n",
    "\n",
    "meta_path = None\n",
    "data_paths = []\n",
    "\n",
    "for pth in all_pths:\n",
    "    if \"meta\" in pth.name.lower():\n",
    "        meta_path = pth\n",
    "    else:\n",
    "        data_paths.append(pth)\n",
    "\n",
    "assert meta_path is not None, \"❌ meta.pth file not found!\"\n",
    "meta = torch.load(meta_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Temp\\ipykernel_9252\\1519225210.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  meta = torch.load(meta_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size : 800, test_size : 100, val_size : 100\n",
      "51 of 200 classes have atleast try_k_shot + try_n_query (10) examples\n",
      "train_size : 800, test_size : 100, val_size : 100\n",
      "12 of 200 classes have atleast try_k_shot + try_n_query (6) examples\n",
      "train_size : 800, test_size : 100, val_size : 100\n",
      "8 of 200 classes have atleast try_k_shot + try_n_query (6) examples\n"
     ]
    }
   ],
   "source": [
    "dataset = ShardedEpisodicDataset(data_paths, meta_path, 5, 5, 5, split=\"train\", min_examples_per_class=15)\n",
    "val_dataset = ShardedEpisodicDataset(data_paths, meta_path, 3, 3, 3, split=\"val\", min_examples_per_class=15)\n",
    "test_dataset = ShardedEpisodicDataset(data_paths, meta_path, 3, 3, 3, split=\"test\", min_examples_per_class=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_regularization(model, lambda_l2=0.001):\n",
    "    l2_norm = 0\n",
    "    for param in model.parameters():\n",
    "        l2_norm += param.pow(2).sum()\n",
    "    return lambda_l2 * l2_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34, ResNet34_Weights\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvEncoder(nn.Module):\n",
    "    def __init__(self, input_shape=(1, 128, 1056)):  # C, H, W — use your typical input size\n",
    "        super().__init__()\n",
    "        self.input_shape = input_shape\n",
    "        model = resnet34(weights=ResNet34_Weights.DEFAULT)\n",
    "        self.features = nn.Sequential(\n",
    "            model.conv1,\n",
    "            model.bn1,\n",
    "            model.relu,\n",
    "            nn.Dropout(p=0.3),\n",
    "            model.maxpool,\n",
    "            model.layer1,\n",
    "            nn.Dropout(p=0.3),\n",
    "            model.layer2,\n",
    "            model.layer3,\n",
    "            model.layer4\n",
    "        )\n",
    "        self.output_channels = 512\n",
    "\n",
    "        # Compute number of tokens after spatial downsampling\n",
    "        # Ensure dummy input has 3 channels for ResNet\n",
    "        dummy_input = torch.zeros((1, 3) + input_shape[1:])\n",
    "        with torch.no_grad():\n",
    "            out = self.features(dummy_input)\n",
    "            _, _, h, w = out.shape\n",
    "            self.max_nodes = h * w\n",
    "\n",
    "        # Positional encoding\n",
    "        self.pos_enc = nn.Parameter(torch.randn(self.max_nodes, self.output_channels) * 0.02)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(self.output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "      original_shape = x.shape\n",
    "      if x.shape[1] == 1:\n",
    "          x = x.repeat(1, 3, 1, 1)  # Convert (B, 1, H, W) → (B, 3, H, W)\n",
    "      x = self.features(x)  # (B, 512, H/32, W/32)\n",
    "      x = x.flatten(2).transpose(1, 2)  # (B, N, 512)\n",
    "\n",
    "      seq_len=x.size(1)\n",
    "      # Adjust positional encoding\n",
    "      if x.size(1) != self.pos_enc.size(0):\n",
    "          pe = F.interpolate(self.pos_enc.unsqueeze(0).transpose(1, 2), size=x.size(1), mode=\"linear\", align_corners=False)\n",
    "          pe = pe.transpose(1, 2).squeeze(0)\n",
    "      else:\n",
    "          pe = self.pos_enc\n",
    "      x = x + pe\n",
    "      x = self.layer_norm(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ProtoNet stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    \"\"\"Compute cosine similarity between two tensors\"\"\"\n",
    "    # Normalize the vectors\n",
    "    x_norm = torch.nn.functional.normalize(x, p=2, dim=1)  # shape: (n, d)\n",
    "    y_norm = torch.nn.functional.normalize(y, p=2, dim=1)  # shape: (m, d)\n",
    "\n",
    "    # Compute cosine similarity: x_norm @ y_norm.T\n",
    "    similarity = torch.mm(x_norm, y_norm.t())  # shape: (n, m)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "  def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "    super().__init__()\n",
    "    self.gamma = gamma\n",
    "    self.alpha = alpha\n",
    "    self.reduction = reduction\n",
    "\n",
    "  def forward(self, logits, targets):\n",
    "    bce_loss = F.binary_cross_entropy_with_logits(logits, targets, reduction='none')\n",
    "    pt = torch.exp(-bce_loss)\n",
    "    focal_loss = ((1 - pt) ** self.gamma) * bce_loss\n",
    "    if self.alpha is not None:\n",
    "      focal_loss = self.alpha * focal_loss\n",
    "    if self.reduction == 'mean':\n",
    "      return focal_loss.mean()\n",
    "    elif self.reduction == 'sum':\n",
    "      return focal_loss.sum()\n",
    "    else:\n",
    "      return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mAP(y_true, y_scores):\n",
    "  num_classes = y_true.shape[1]\n",
    "  APs = []\n",
    "  for i in range(num_classes):\n",
    "    if np.sum(y_true[:, i]) >0:\n",
    "      AP = average_precision_score(y_true[:, i], y_scores[:, i])\n",
    "      APs.append(AP)\n",
    "  return np.mean(APs) if len(APs) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_grad_embeddings(model, data, batch_size):\n",
    "    embeddings = []\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        mini_batch = data[i:i+batch_size]\n",
    "        embed = model(mini_batch)\n",
    "        embeddings.append(embed)\n",
    "    return torch.cat(embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prototypical_loss(model, episode, device, use_focal=True, alpha=1.0, gamma=2.0, temperature=0.4,\n",
    "                      max_subset_size=3, max_num_subsets=500, ema_prototypes=None, ema_momentum=0.25):\n",
    "    \"\"\"\n",
    "    Fixed prototypical loss with temperature scaling to handle distance-based logits properly.\n",
    "\n",
    "    Args:\n",
    "        temperature: Scale factor for distances. Try values between 0.1 and 10.0\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    support_label = episode['support_label'].to(device)\n",
    "    query_label = episode['query_label'].to(device)\n",
    "    support_data = episode['support_data'].to(device)\n",
    "    query_data = episode['query_data'].to(device)\n",
    "\n",
    "    def get_power_set(indices, max_len=max_subset_size):\n",
    "        s = list(indices)\n",
    "        return list(chain.from_iterable(combinations(s, r) for r in range(1, min(len(s), max_len) + 1)))\n",
    "\n",
    "    # Gather unique label combinations\n",
    "    unique_combos = set()\n",
    "    for lbl in torch.cat([support_label, query_label], 0):\n",
    "        active = tuple(i for i, v in enumerate(lbl) if v == 1)\n",
    "        if active:\n",
    "            unique_combos.add(active)\n",
    "\n",
    "    all_subsets = set()\n",
    "    for combo in unique_combos:\n",
    "        for r in range(1, min(len(combo), max_subset_size)+1):\n",
    "            for sub in combinations(combo, r):\n",
    "                all_subsets.add(tuple(sorted(sub)))\n",
    "\n",
    "    all_subsets = sorted(all_subsets, key=lambda s: (len(s), s))\n",
    "    if len(all_subsets) > max_num_subsets:\n",
    "        all_subsets = all_subsets[:max_num_subsets]\n",
    "\n",
    "    subset_map = {s: i for i, s in enumerate(all_subsets)}\n",
    "\n",
    "    def extend_labels(lbls):\n",
    "        ext = torch.zeros((lbls.size(0), len(subset_map)), device=device)\n",
    "        for i, row in enumerate(lbls):\n",
    "            active = [j for j,v in enumerate(row) if v==1]\n",
    "            for r in range(1, min(len(active), max_subset_size)+1):\n",
    "                for sub in combinations(active, r):\n",
    "                    idx = subset_map.get(tuple(sorted(sub)))\n",
    "                    if idx is not None:\n",
    "                        ext[i, idx] = 1\n",
    "        return ext\n",
    "\n",
    "    support_ext = extend_labels(support_label)\n",
    "    query_ext   = extend_labels(query_label)\n",
    "\n",
    "    # Get embeddings\n",
    "    support_emb = compute_grad_embeddings(model, support_data, batch_size=4)\n",
    "    query_emb   = compute_grad_embeddings(model, query_data, batch_size=4)\n",
    "\n",
    "    # Vectorized prototype averaging\n",
    "    w = support_ext.T  # (num_proto, num_support)\n",
    "    protos_cur = (w @ support_emb) / w.sum(dim=1, keepdim=True).clamp(min=1)\n",
    "\n",
    "    protos = []\n",
    "    for i, key in enumerate(subset_map.keys()):\n",
    "        vec = protos_cur[i]\n",
    "        if ema_prototypes is not None:\n",
    "            if key not in ema_prototypes:\n",
    "                ema_prototypes[key] = vec.clone().detach()\n",
    "            else:\n",
    "                ema_prototypes[key] = (\n",
    "                    (1 - ema_momentum) * ema_prototypes[key] +\n",
    "                    ema_momentum * vec.detach()\n",
    "                )\n",
    "            protos.append(ema_prototypes[key])\n",
    "        else:\n",
    "            protos.append(vec)\n",
    "\n",
    "    protos = torch.stack(protos).detach()\n",
    "\n",
    "    query_emb = F.normalize(query_emb, dim=1)\n",
    "    protos = F.normalize(protos, dim=1)\n",
    "\n",
    "    # CRITICAL FIX: Apply temperature scaling to distances\n",
    "    dists = torch.matmul(query_emb, protos.T)       # (B, P)\n",
    "\n",
    "# Optional: scale similarity\n",
    "    logits = dists / temperature       # <-- This is the key fix!\n",
    "\n",
    "    # Alternative approaches you can try:\n",
    "    # Option 1: Normalize embeddings first (cosine similarity)\n",
    "    # query_emb_norm = F.normalize(query_emb, dim=1)\n",
    "    # protos_norm = F.normalize(protos, dim=1)\n",
    "    # logits = torch.mm(query_emb_norm, protos_norm.T)  # Cosine similarity\n",
    "\n",
    "    # Option 2: Gaussian kernel\n",
    "    # logits = -dists.pow(2) / (2 * temperature**2)\n",
    "\n",
    "    # Enhanced diagnostics\n",
    "    with torch.no_grad():\n",
    "        print(f\"Distance range: [{dists.min().item():.4f}, {dists.max().item():.4f}]\")\n",
    "        print(f\"Logits range: [{logits.min().item():.4f}, {logits.max().item():.4f}]\")\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        print(f\"Probabilities range: [{probs.min().item():.6f}, {probs.max().item():.6f}]\")\n",
    "        print(f\"Prob mean: {probs.mean().item():.6f}\")\n",
    "        print(f\"[Train] Avg Logit Range: {logits.min().item()} to {logits.max().item()}\")\n",
    "        print(f\"[Train] Avg Prob Mean: {probs.mean().item()}\")\n",
    "        y_true = query_ext.cpu().numpy()\n",
    "        y_probs = probs.cpu().numpy()\n",
    "\n",
    "        # Test multiple thresholds\n",
    "        for thresh in [0.2]:\n",
    "            y_pred = (y_probs > thresh).astype(int)\n",
    "            valid_classes = y_true.sum(axis=0) > 0\n",
    "            if valid_classes.sum() > 0:\n",
    "                y_true_valid = y_true[:, valid_classes]\n",
    "                y_pred_valid = y_pred[:, valid_classes]\n",
    "                f1 = f1_score(y_true_valid, y_pred_valid, average='macro', zero_division=0)\n",
    "                print(f\"F1 at threshold {thresh}: {f1:.4f}\")\n",
    "\n",
    "    # Loss calculation\n",
    "    if use_focal:\n",
    "        pos_freq = query_ext.float().mean(0)\n",
    "        eps = 1e-6\n",
    "        alpha = pos_freq  # Use positive frequency directly as alpha\n",
    "        loss_fn = FocalLoss(gamma=gamma, alpha=alpha)\n",
    "    else:\n",
    "        # Add class balancing for BCEWithLogitsLoss too\n",
    "        pos_freq = query_ext.float().mean(0)\n",
    "        pos_weight = (1 - pos_freq) / (pos_freq + 1e-6)\n",
    "        pos_weight = torch.clamp(pos_weight, max=10.0)\n",
    "        loss_fn = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    loss = loss_fn(logits, query_ext.float())\n",
    "\n",
    "    # Proper evaluation metrics\n",
    "    with torch.no_grad():\n",
    "        probs = torch.sigmoid(logits)\n",
    "        y_true = query_ext.cpu().numpy()\n",
    "\n",
    "        # mAP calculation (this should now work properly)\n",
    "        APs = []\n",
    "        for i in range(len(subset_map)):\n",
    "            if y_true[:, i].sum() > 0:  # Only classes with positive samples\n",
    "                ap = average_precision_score(y_true[:, i], probs[:, i].cpu().numpy())\n",
    "                APs.append(ap)\n",
    "\n",
    "        mAP = float(np.mean(APs)) if APs else 0.0\n",
    "        print(f\"Number of valid classes for mAP: {len(APs)}\")\n",
    "        print(f\"mAP: {mAP:.4f}\")\n",
    "\n",
    "        # F1 score (fixed - no flattening for multi-label)\n",
    "        y_pred = (probs > 0.5).cpu().numpy().astype(int)\n",
    "\n",
    "        # Only compute F1 on classes with positive samples\n",
    "        valid_classes = y_true.sum(axis=0) > 0\n",
    "        if valid_classes.sum() > 0:\n",
    "            f1 = f1_score(y_true[:, valid_classes], y_pred[:, valid_classes],\n",
    "                         average='macro', zero_division=0)\n",
    "        else:\n",
    "            f1 = 0.0\n",
    "\n",
    "    return loss, f1, mAP\n",
    "\n",
    "  # # Apply sigmoid and compute loss using BCE\n",
    "  # #print(distances.shape)\n",
    "  # #print(query_ext_lbls.float().shape)\n",
    "  # pos_freq = query_ext_lbls.float().mean(dim=0)\n",
    "  # epsilon = 1e-6\n",
    "  # raw_pos_weight = 1.0 / (pos_freq + epsilon)\n",
    "  # max_weight = 10.0\n",
    "  # pos_weight  = torch.clamp(raw_pos_weight, max = max_weight)\n",
    "  # loss_fn = nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
    "  # loss = loss_fn(distances, query_ext_lbls.float())\n",
    "\n",
    "  # # compress the extended prediction back to normal\n",
    "  # pred = torch.zeros(episode['query_data'].shape[0], num_classes, dtype=torch.bool, device=device)\n",
    "  # for i in range(episode['query_data'].shape[0]):\n",
    "  #   min_dist = torch.min(distances[i])  # 1. Get smallest distance value for this query\n",
    "  #   candidates = (distances[i] == min_dist).nonzero(as_tuple=True)[0]  # 2. Find ALL prototypes with this distance\n",
    "  #   best_idx = max(candidates, key=lambda idx: len(all_subsets[idx]))  # 3. Select largest subset\n",
    "  #   pred[i, all_subsets[best_idx]] = True\n",
    "\n",
    "  # true_bool = episode['query_label'].to(device).bool()\n",
    "  # tp = (pred & true_bool).sum().float()\n",
    "  # fp = (pred & ~true_bool).sum().float()\n",
    "  # fn = (~pred & true_bool).sum().float()\n",
    "\n",
    "  # precision = tp / (tp + fp + 1e-6)  # Adding small value to avoid division by zero\n",
    "  # recall = tp / (tp + fn + 1e-6)\n",
    "  # f1_score = 2 * (precision * recall) / (precision + recall + 1e-6)\n",
    "\n",
    "  # return loss, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, episode, device):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    num_classes = episode['support_label'].shape[1]\n",
    "    unique_combinations = set()\n",
    "\n",
    "    # Collect unique combinations from both support and query\n",
    "    for label_set in episode['support_label']:\n",
    "        active = tuple(i for i, val in enumerate(label_set) if val == 1)\n",
    "        if active:\n",
    "            unique_combinations.add(active)\n",
    "    for label_set in episode['query_label']:\n",
    "        active = tuple(i for i, val in enumerate(label_set) if val == 1)\n",
    "        if active:\n",
    "            unique_combinations.add(active)\n",
    "\n",
    "    def get_power_set(indices):\n",
    "        return list(chain.from_iterable(combinations(indices, r) for r in range(1, len(indices) + 1)))\n",
    "\n",
    "    # Generate all subsets\n",
    "    all_subsets = set()\n",
    "    for idx_comb in unique_combinations:\n",
    "        for subset in get_power_set(idx_comb):\n",
    "            all_subsets.add(tuple(sorted(subset)))\n",
    "    all_subsets = sorted(all_subsets, key=lambda s: (len(s), s))\n",
    "    subset_map = {subset: i for i, subset in enumerate(all_subsets)}\n",
    "\n",
    "    def extend_labels(labels):\n",
    "        ext = torch.zeros((len(labels), len(all_subsets)), dtype=torch.float, device=device)\n",
    "        for i, row in enumerate(labels):\n",
    "            active_indices = tuple(sorted(j for j, val in enumerate(row) if val == 1))\n",
    "            if active_indices:\n",
    "                for subset in get_power_set(active_indices):\n",
    "                    subset = tuple(sorted(subset))\n",
    "                    ext[i, subset_map[subset]] = 1.0\n",
    "        return ext\n",
    "\n",
    "    support_ext_lbls = extend_labels(episode['support_label'])\n",
    "    query_ext_lbls = extend_labels(episode['query_label'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        support_embeddings = model(episode['support_data'].to(device))\n",
    "        query_embeddings = model(episode['query_data'].to(device))\n",
    "\n",
    "    d = support_embeddings.shape[1]\n",
    "    num_proto = len(all_subsets)\n",
    "    prototypes = torch.zeros((num_proto, d), device=device)\n",
    "    counts = torch.zeros(num_proto, device=device)\n",
    "\n",
    "    # Build prototypes\n",
    "    for i in range(support_embeddings.shape[0]):\n",
    "        active_prototypes = support_ext_lbls[i].nonzero(as_tuple=True)[0]\n",
    "        for p in active_prototypes:\n",
    "            prototypes[p] += support_embeddings[i]\n",
    "            counts[p] += 1\n",
    "\n",
    "    counts = counts.clamp(min=1)\n",
    "    prototypes /= counts.unsqueeze(1)\n",
    "\n",
    "    # Debug prototype information\n",
    "    prototype_norms = torch.norm(prototypes, dim=1)\n",
    "    query_norms = torch.norm(query_embeddings, dim=1)\n",
    "\n",
    "    print(f\"  Prototype norms - min: {prototype_norms.min():.6f}, max: {prototype_norms.max():.6f}, mean: {prototype_norms.mean():.6f}\")\n",
    "    print(f\"  Query norms - min: {query_norms.min():.6f}, max: {query_norms.max():.6f}, mean: {query_norms.mean():.6f}\")\n",
    "    print(f\"  Prototypes with zero norm: {(prototype_norms == 0).sum().item()}/{len(prototypes)}\")\n",
    "\n",
    "    # Compute cosine similarity and logits\n",
    "    similarities = cosine_similarity(query_embeddings, prototypes)\n",
    "\n",
    "    print(f\"  Cosine similarities - min: {similarities.min():.6f}, max: {similarities.max():.6f}, mean: {similarities.mean():.6f}\")\n",
    "\n",
    "    logits = similarities  # cosine similarity is already in [-1, 1] range\n",
    "    probs_extended = torch.sigmoid(logits)\n",
    "\n",
    "    print(f\"  Logits - min: {logits.min():.6f}, max: {logits.max():.6f}\")\n",
    "    print(f\"  Extended probs - min: {probs_extended.min():.6f}, max: {probs_extended.max():.6f}\")\n",
    "\n",
    "    # Convert back to original label space using WEIGHTED AVERAGE approach\n",
    "    original_probs = torch.zeros((query_embeddings.shape[0], num_classes), device=device)\n",
    "\n",
    "    # For each query and each class, aggregate probabilities from subsets containing that class\n",
    "    for i in range(query_embeddings.shape[0]):  # for each query sample\n",
    "        for j in range(num_classes):  # for each original class\n",
    "            # Find all extended labels that include this original class\n",
    "            class_probs = []\n",
    "            class_weights = []\n",
    "\n",
    "            for subset_idx, subset in enumerate(all_subsets):\n",
    "                if j in subset:\n",
    "                    # Weight by inverse subset size (smaller subsets = more specific = higher weight)\n",
    "                    weight = 1.0 / len(subset)\n",
    "                    class_probs.append(probs_extended[i, subset_idx].item())\n",
    "                    class_weights.append(weight)\n",
    "\n",
    "            if class_probs:\n",
    "                # Weighted average instead of max\n",
    "                weighted_prob = sum(p * w for p, w in zip(class_probs, class_weights)) / sum(class_weights)\n",
    "                original_probs[i, j] = weighted_prob\n",
    "\n",
    "    # Generate predictions for original classes\n",
    "    original_pred = (original_probs > 0.5).int()\n",
    "\n",
    "    return original_pred, original_probs, episode['query_label'], query_ext_lbls, all_subsets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAT stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    def __init__(self, c_in, c_out, num_heads=8, alpha=0.3, top_k=5, concat_heads = True):\n",
    "        super().__init__()\n",
    "        assert c_out % num_heads == 0, \"c_out must be divisible by num_heads\"\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = c_out // num_heads\n",
    "        self.c_out = c_out\n",
    "        self.top_k = top_k\n",
    "        self.concat_heads = concat_heads\n",
    "\n",
    "        self.projection = nn.Linear(c_in, c_out, bias=False)\n",
    "        self.a = nn.Parameter(torch.Tensor(num_heads, 2 * self.head_dim))\n",
    "        self.leakyrelu = nn.LeakyReLU(alpha)\n",
    "\n",
    "        # Add output projection layer\n",
    "        if concat_heads:\n",
    "            self.output_project = nn.Linear(c_out, c_out)\n",
    "        else:\n",
    "            self.output_project = nn.Linear(self.head_dim, c_out)\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(c_out)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.projection.weight, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.a, gain=1.414)\n",
    "        nn.init.xavier_uniform_(self.output_project.weight, gain=1.414)\n",
    "        nn.init.zeros_(self.output_project.bias)\n",
    "\n",
    "    def compute_adj_matrix(self, feats, drop_prob=0.3):\n",
    "        B, N, _ = feats.shape\n",
    "        # Normalize features along the last dimension (using lowercase 'normalize')\n",
    "        norm_feats = F.normalize(feats, p=2, dim=-1)\n",
    "        # Here, node_feats has shape (batch_size, num_nodes, feature_dim).\n",
    "        # We need to compute pairwise similarity per batch.\n",
    "        # Use torch.bmm to perform batched matrix multiplication.\n",
    "        sim = torch.bmm(norm_feats, norm_feats.transpose(1, 2))  # (batch, num_nodes, num_nodes)\n",
    "        # Create a binary adjacency matrix based on a threshold (e.g., 0.5)\n",
    "        if self.top_k is not None:\n",
    "          topk_values, top_k_indices = torch.topk(sim, k=min(self.top_k+1, N), dim=-1)\n",
    "          mask = torch.zeros_like(sim)\n",
    "          mask.scatter_(2, top_k_indices, 1.0)\n",
    "\n",
    "          eye = torch.eye(N, device=sim.device).unsqueeze(0).expand(B, -1, -1)\n",
    "          mask = torch.maximum(mask, eye)\n",
    "          sim = sim * mask\n",
    "\n",
    "        adj_matrix = (sim > 0.3).float()\n",
    "\n",
    "        if drop_prob > 0.0:\n",
    "          eye = torch.eye(N, device=adj_matrix.device).unsqueeze(0).expand(B, -1, -1)\n",
    "          drop_mask = (torch.rand_like(adj_matrix) > drop_prob).float()\n",
    "          drop_mask = torch.maximum(drop_mask, eye)\n",
    "          adj_matrix = adj_matrix * drop_mask\n",
    "\n",
    "        return adj_matrix\n",
    "\n",
    "    def forward(self, feats, print_attn_probs=False):\n",
    "        batch_size, num_nodes, _ = feats.shape\n",
    "\n",
    "        # Compute the adjacency matrix from node features.\n",
    "        adj_matrix = self.compute_adj_matrix(feats, drop_prob=0.2)  # Expected shape: (batch_size, num_nodes, num_nodes)\n",
    "\n",
    "        projected_feats = self.projection(feats)  # (B, N, heads * d_head)\n",
    "        residual = feats if feats.shape[-1] == self.c_out else None\n",
    "        node_feats = projected_feats.view(batch_size, num_nodes, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Now, get the indices of nonzero elements in the adj matrix.\n",
    "        # Note: For a batched adj_matrix, nonzero() returns indices with shape (num_edges, 3)\n",
    "        # edges[:, 0] is the batch index, edges[:, 1] is the row index, and edges[:, 2] is the column index.\n",
    "        edges = (adj_matrix > 0.0).nonzero(as_tuple=False)\n",
    "        if edges.size(0) == 0:\n",
    "            # Handle case where no edges exist\n",
    "            output = projected_feats\n",
    "            if not self.concat_heads:\n",
    "                output = node_feats.mean(dim=2)\n",
    "            output = self.output_project(output)\n",
    "            output = self.layer_norm(output + residual)\n",
    "            return output\n",
    "\n",
    "        batch_indices = edges[:, 0]\n",
    "        offset = batch_indices * num_nodes\n",
    "        edges_indices_row = offset + edges[:, 1]\n",
    "        edges_indices_col = offset + edges[:, 2]\n",
    "\n",
    "        node_feats_flat = node_feats.view(batch_size * num_nodes, self.num_heads, self.head_dim)\n",
    "\n",
    "        a_input = torch.cat([\n",
    "            torch.index_select(node_feats_flat, dim=0, index=edges_indices_row),\n",
    "            torch.index_select(node_feats_flat, dim=0, index=edges_indices_col)\n",
    "        ], dim=-1)\n",
    "\n",
    "        attn_logits = torch.einsum('ehd,hd->eh', a_input, self.a)\n",
    "        attn_logits = self.leakyrelu(attn_logits)\n",
    "\n",
    "\n",
    "        # Create an attention matrix with shape (batch_size, num_nodes, num_nodes, num_heads)\n",
    "        attn_matrix = torch.full((batch_size, num_nodes, num_nodes, self.num_heads), -1e9, device=node_feats.device, dtype=node_feats.dtype)\n",
    "        # Assign computed logits to positions where adj_matrix is 1.\n",
    "        # We expand adj_matrix to have a head dimension.\n",
    "        for i, (b, r, c) in enumerate(edges):\n",
    "            attn_matrix[b, r, c, :] = attn_logits[i, :]\n",
    "\n",
    "        attn_probs = F.softmax(attn_matrix, dim=2)\n",
    "\n",
    "        if self.training:\n",
    "            attn_probs = self.dropout_layer(attn_probs)\n",
    "\n",
    "        if print_attn_probs:\n",
    "            print(\"Attention probabilities shape:\", attn_probs.shape)\n",
    "            print(\"Sample attention probs:\\n\", attn_probs[0, :5, :5, 0].detach().cpu())\n",
    "\n",
    "        aggr_feats = torch.einsum('bnmh,bmhd->bnhd', attn_probs, node_feats)\n",
    "\n",
    "        if self.concat_heads:\n",
    "            output = aggr_feats.reshape(batch_size, num_nodes, -1)\n",
    "        else:\n",
    "            output = aggr_feats.mean(dim=2)\n",
    "\n",
    "        output = self.output_project(output)\n",
    "\n",
    "        if residual is not None and output.shape == residual.shape:\n",
    "            output = self.layer_norm(output + residual)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CnnGat(nn.Module):\n",
    "    def __init__(self, cnn_encoder, gat_layer, per_node_dim, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "\n",
    "        # 1) Encoder on CPU initially\n",
    "        self.cnn_encoder = cnn_encoder()\n",
    "\n",
    "        # 2) Compute N on CPU\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 1, 128, 1056)   # **no .to(device) here**\n",
    "            N = self.cnn_encoder(dummy).size(1)    # gets number of nodes\n",
    "\n",
    "        # 3) GAT on CPU too\n",
    "        self.gat_layer = gat_layer(\n",
    "            c_in=self.cnn_encoder.output_channels,\n",
    "            c_out=per_node_dim\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(N * per_node_dim)\n",
    "\n",
    "\n",
    "    def forward(self, data):\n",
    "        small_bs = 4\n",
    "        B = data.size(0)\n",
    "        encoded = []\n",
    "\n",
    "        # 1) Batch through encoder to avoid OOM\n",
    "        for i in range(0, B, small_bs):\n",
    "            chunk = data[i:i+small_bs].to(self.device)\n",
    "            with torch.no_grad():\n",
    "                out = self.cnn_encoder(chunk)  # <-- (miniB, N, D)\n",
    "            encoded.append(out)\n",
    "        # 2) concatenate back into (B, N, D)\n",
    "        node_feats = torch.cat(encoded, dim=0)  # (B, N, D)\n",
    "        # 3) GAT over nodes → (B, N, d'), where N = nodes per sample\n",
    "        gat_out = self.gat_layer(node_feats)    # (B, N, d')\n",
    "        # 4) flatten to (B, N * d') = (B, embed_size)\n",
    "        flat = gat_out.reshape(B, -1)           # (B, embed_size)\n",
    "        # 5) optional layer norm\n",
    "        return self.norm(flat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import random\n",
    "\n",
    "ema_prototypes = {}\n",
    "def check_val(model, val_dataset, ema_prototypes, num_checks=10):\n",
    "    model.eval()  # Set to evaluation mode\n",
    "\n",
    "    running_f1 = 0.0\n",
    "    min_f1 = float('inf')\n",
    "    max_f1 = float('-inf')\n",
    "\n",
    "    running_map = 0.0\n",
    "    min_map = float('inf')  # Add min/max tracking for mAP\n",
    "    max_map = float('-inf')\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for i in range(num_checks):\n",
    "            test_ep = val_dataset[0]\n",
    "            _, f1, mAP = prototypical_loss(model, test_ep, device, use_focal=True, gamma=2.0, alpha=1.0, ema_prototypes=ema_prototypes, ema_momentum=0.25)\n",
    "\n",
    "            f1_val = f1.item() if torch.is_tensor(f1) else f1\n",
    "            mAP_val = mAP.item() if torch.is_tensor(mAP) else mAP\n",
    "\n",
    "            running_f1 += f1_val\n",
    "            running_map += mAP_val\n",
    "\n",
    "            min_f1 = min(min_f1, f1_val)\n",
    "            max_f1 = max(max_f1, f1_val)\n",
    "            min_map = min(min_map, mAP_val)  # Track mAP min/max\n",
    "            max_map = max(max_map, mAP_val)\n",
    "\n",
    "    model.train()  # Switch back to training mode\n",
    "\n",
    "    avg_f1 = running_f1 / num_checks\n",
    "    avg_map = running_map / num_checks\n",
    "\n",
    "    print(f\"\\nVal: Avg F1: {avg_f1:.2f}, min: {min_f1:.2f}, max: {max_f1:.2f}\")\n",
    "    print(f\"Val: Avg mAP: {avg_map:.2f}, min: {min_map:.2f}, max: {max_map:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, val_dataset, optimizer, batch_size, epochs, device):\n",
    "  model.train()\n",
    "  model.to(device)\n",
    "\n",
    "  random.seed(42)\n",
    "  torch.manual_seed(42)\n",
    "\n",
    "  scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-5)\n",
    "\n",
    "  for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    running_f1 = 0.0\n",
    "    running_mAP = 0.0\n",
    "    for batch in tqdm(range(batch_size)):\n",
    "      optimizer.zero_grad()\n",
    "      episode = dataset[0] # the indexing on our custom dataset is nonsense on purpose, every index gives random result each time\n",
    "\n",
    "      loss, f1, mAP = prototypical_loss(model, episode, device, use_focal=True, gamma=2.0, alpha=1.0, ema_prototypes=ema_prototypes, ema_momentum=0.25)\n",
    "      loss += l2_regularization(model, lambda_l2=1e-5)\n",
    "      loss.backward()\n",
    "      torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item()\n",
    "      running_f1 += f1.item() if torch.is_tensor(f1) else f1\n",
    "      running_mAP += mAP.item() if torch.is_tensor(mAP) else mAP\n",
    "\n",
    "      del episode, loss, f1\n",
    "      gc.collect()\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss = running_loss / batch_size\n",
    "    epoch_f1 = running_f1 / batch_size\n",
    "    epoch_mAP = running_mAP / batch_size\n",
    "    print(f'\\nEpoch {epoch+1} Complete - Loss: {epoch_loss:.4f} F1: {epoch_f1:.2f} mAP: {epoch_mAP:.2f}\\n')\n",
    "    check_val(model, val_dataset, ema_prototypes)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aniru\\.conda\\envs\\pytorch-env\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c194dbb0587e4268ad8279b8eb6a0cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Complete - Loss: 4502.7261 F1: 0.00 mAP: 0.05\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89206f00fd54fdfa02c7b91555095d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Complete - Loss: 3707.6733 F1: 0.00 mAP: 0.06\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa147cb6f14f426ba1ab77a91c0a6450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Complete - Loss: 1662.2552 F1: 0.00 mAP: 0.09\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f9f70262ea42e7b134d46832b216d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Complete - Loss: 3071.6277 F1: 0.00 mAP: 0.08\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd18a372de194cf8b05b6d99601df744",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Complete - Loss: 1270.9792 F1: 0.00 mAP: 0.07\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f67db352224349a6590063b9a4d74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Complete - Loss: 1546.6217 F1: 0.00 mAP: 0.09\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbb7fc54e7f4c9dadb82644a22c2e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Complete - Loss: 735.5558 F1: 0.00 mAP: 0.06\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5285816ca6b1480591fe60ddc6862ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Complete - Loss: 418.1100 F1: 0.00 mAP: 0.07\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "856c1838f4d24c6b82e676a39a51e6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Complete - Loss: 584.7097 F1: 0.00 mAP: 0.09\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848cc57c21884c2095df722cc4e25f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Complete - Loss: 377.0464 F1: 0.00 mAP: 0.07\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70980e26c82a4aa4af6d01aa95bc9ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Complete - Loss: 257.7603 F1: 0.00 mAP: 0.10\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fab62837f73d4f299787d5a2971a9dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Complete - Loss: 716.4217 F1: 0.00 mAP: 0.10\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e941a437a3764f67a0afb9dafc2d3451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Complete - Loss: 325.2314 F1: 0.00 mAP: 0.27\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92198dbf71864889bf3cda90d8b09a55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Complete - Loss: 483.9039 F1: 0.00 mAP: 0.13\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31f963f78b0422fb6ee159d348e89e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Complete - Loss: 171.1426 F1: 0.00 mAP: 0.05\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde153989d254e929716f256711f13e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Complete - Loss: 361.3249 F1: 0.00 mAP: 0.25\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02360a7872a142b0a72553a4a6496506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Complete - Loss: 179.9952 F1: 0.00 mAP: 0.16\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87190cfd00ba48589e162833b799cb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Complete - Loss: 87.4403 F1: 0.00 mAP: 0.16\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f134a64396374920905b5dbc007829f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Complete - Loss: 185.4249 F1: 0.00 mAP: 0.17\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1f553d9e944f6f9d05eb3334b77f3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Complete - Loss: 196.8330 F1: 0.00 mAP: 0.48\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0344ffdaa42c4610bf0805299f739df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Complete - Loss: 230.9429 F1: 0.00 mAP: 0.20\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed61eeabc02c4f409b1353b2891da8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Complete - Loss: 183.2174 F1: 0.00 mAP: 0.22\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97e2c95d38d4bb089b953db94694b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Complete - Loss: 86.4002 F1: 0.00 mAP: 0.39\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "100823b4f4b549e182df74ebf4e04b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Complete - Loss: 145.1480 F1: 0.00 mAP: 0.37\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc12f8abf0954d908d2e46b69db1148e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Complete - Loss: 101.4964 F1: 0.00 mAP: 0.26\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d92f36f8a74bf5a832540492102d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Complete - Loss: 88.2247 F1: 0.00 mAP: 0.30\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e1b35b0357945cbaf90ea6cd3caebe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Complete - Loss: 55.5996 F1: 0.00 mAP: 0.69\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac29f878f1f046f4bc1f6587165b32e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Complete - Loss: 95.7957 F1: 0.00 mAP: 0.38\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b63fc377674968abaa9acbc35a6304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Complete - Loss: 93.7661 F1: 0.00 mAP: 0.15\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d468f7ac998b4f8086d72d05788fbead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Complete - Loss: 129.3657 F1: 0.00 mAP: 0.46\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc3aca8288994b28a60f040834b7559d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Complete - Loss: 90.3758 F1: 0.00 mAP: 0.26\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9b9fd3304c41a49f49dbed04beec6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Complete - Loss: 60.5017 F1: 0.00 mAP: 0.30\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9973c211a9d742848c186896fcb6d01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Complete - Loss: 41.7539 F1: 0.00 mAP: 0.61\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c6184b8a0f40d3a1ea0a39d68c079d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Complete - Loss: 49.8972 F1: 0.00 mAP: 0.42\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe07eb24a6464944a94662b5fd30f8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Complete - Loss: 49.9561 F1: 0.00 mAP: 0.46\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4df2926212fe433aa94a5eca1cefe1a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Complete - Loss: 71.9424 F1: 0.00 mAP: 0.39\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e964a17c0b6422a83eac171d6ae9e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Complete - Loss: 45.9229 F1: 0.00 mAP: 0.60\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e69a78bfa3481c9fb00a40ed526084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Complete - Loss: 51.7622 F1: 0.00 mAP: 0.38\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d959012992a84932b61e7ad1f9868e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Complete - Loss: 89.0727 F1: 0.00 mAP: 0.47\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a7e5133cd8441f96c078c2789b5235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Complete - Loss: 95.4495 F1: 0.00 mAP: 0.66\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb55df61cf934676a98441e2c55431ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Complete - Loss: 59.9724 F1: 0.00 mAP: 0.67\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345ca2cf74804d3aaa62eb8bd37a77f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Complete - Loss: 61.2763 F1: 0.00 mAP: 0.64\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2926ffb61748d3837febc8c4a22b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Complete - Loss: 64.1643 F1: 0.00 mAP: 0.32\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9385bbc186849eaa3051ddb4cffbfbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Complete - Loss: 51.6828 F1: 0.00 mAP: 0.46\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5236835480b04b5ca2252c6f194e9409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Complete - Loss: 57.7208 F1: 0.00 mAP: 0.57\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f07a56b8cc4df4afb370b0fdcc3147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Complete - Loss: 45.3970 F1: 0.00 mAP: 0.53\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707b94003e094537a48ca2830a10d04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Complete - Loss: 52.3434 F1: 0.00 mAP: 0.59\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675dfd702c544ac0bc976aa33e25d03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Complete - Loss: 36.1054 F1: 0.00 mAP: 0.49\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db59672c9b974929878fc6de3cd240a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Complete - Loss: 33.8246 F1: 0.00 mAP: 0.62\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d481f2d6f91a44c3b7e442c94ffd6387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Complete - Loss: 40.6560 F1: 0.00 mAP: 0.70\n",
      "Val: Avg F1: 0.00, min: 0.00, max: 0.00, Avg mAP: 0.41\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CnnGat(ConvEncoder, GATLayer, per_node_dim=64, device=device)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = 3e-4, weight_decay=1e-4)\n",
    "\n",
    "train(model, dataset, val_dataset, optimizer, batch_size=4, epochs=25, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aniru\\AppData\\Local\\Temp\\ipykernel_9252\\1519225210.py:83: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  shard = torch.load(shard_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 3, 224, 224]), torch.Size([9, 200]), torch.Size([9, 3, 224, 224]), torch.Size([9, 200])\n"
     ]
    }
   ],
   "source": [
    "test_episode = test_dataset[0]\n",
    "\n",
    "support_data = test_episode['support_data']\n",
    "support_label = test_episode['support_label']\n",
    "query_data = test_episode['query_data']\n",
    "query_label = test_episode['query_label']\n",
    "\n",
    "# print shape for debugging\n",
    "print(f\"{test_episode['support_data'].shape}, {test_episode['support_label'].shape}, {test_episode['query_data'].shape}, {test_episode['query_label'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data for visualization\n",
    "imgs = test_episode['query_data'].cpu().numpy().transpose(0, 2, 3, 1)\n",
    "col_names = ['Accelerating_and_revving_and_vroom', 'Accordion', 'Acoustic_guitar', 'Aircraft', 'Alarm', 'Animal', 'Applause', 'Bark', 'Bass_drum', 'Bass_guitar', 'Bathtub_(filling_or_washing)', 'Bell', 'Bicycle', 'Bicycle_bell', 'Bird', 'Bird_vocalization_and_bird_call_and_bird_song', 'Boat_and_Water_vehicle', 'Boiling', 'Boom', 'Bowed_string_instrument', 'Brass_instrument', 'Breathing', 'Burping_and_eructation', 'Bus', 'Buzz', 'Camera', 'Car', 'Car_passing_by', 'Cat', 'Chatter', 'Cheering', 'Chewing_and_mastication', 'Chicken_and_rooster', 'Child_speech_and_kid_speaking', 'Chime', 'Chink_and_clink', 'Chirp_and_tweet', 'Chuckle_and_chortle', 'Church_bell', 'Clapping', 'Clock', 'Coin_(dropping)', 'Computer_keyboard', 'Conversation', 'Cough', 'Cowbell', 'Crack', 'Crackle', 'Crash_cymbal', 'Cricket', 'Crow', 'Crowd', 'Crumpling_and_crinkling', 'Crushing', 'Crying_and_sobbing', 'Cupboard_open_or_close', 'Cutlery_and_silverware', 'Cymbal', 'Dishes_and_pots_and_pans', 'Dog', 'Domestic_animals_and_pets', 'Domestic_sounds_and_home_sounds', 'Door', 'Doorbell', 'Drawer_open_or_close', 'Drill', 'Drip', 'Drum', 'Drum_kit', 'Electric_guitar', 'Engine', 'Engine_starting', 'Explosion', 'Fart', 'Female_singing', 'Female_speech_and_woman_speaking', 'Fill_(with_liquid)', 'Finger_snapping', 'Fire', 'Fireworks', 'Fixed-wing_aircraft_and_airplane', 'Fowl', 'Frog', 'Frying_(food)', 'Gasp', 'Giggle', 'Glass', 'Glockenspiel', 'Gong', 'Growling', 'Guitar', 'Gull_and_seagull', 'Gunshot_and_gunfire', 'Gurgling', 'Hammer', 'Hands', 'Harmonica', 'Harp', 'Hi-hat', 'Hiss', 'Human_group_actions', 'Human_voice', 'Idling', 'Insect', 'Keyboard_(musical)', 'Keys_jangling', 'Knock', 'Laughter', 'Liquid', 'Livestock_and_farm_animals_and_working_animals', 'Male_singing', 'Male_speech_and_man_speaking', 'Mallet_percussion', 'Marimba_and_xylophone', 'Mechanical_fan', 'Mechanisms', 'Meow', 'Microwave_oven', 'Motor_vehicle_(road)', 'Motorcycle', 'Music', 'Musical_instrument', 'Ocean', 'Organ', 'Packing_tape_and_duct_tape', 'Percussion', 'Piano', 'Plucked_string_instrument', 'Pour', 'Power_tool', 'Printer', 'Purr', 'Race_car_and_auto_racing', 'Rail_transport', 'Rain', 'Raindrop', 'Ratchet_and_pawl', 'Rattle', 'Rattle_(instrument)', 'Respiratory_sounds', 'Ringtone', 'Run', 'Sawing', 'Scissors', 'Scratching_(performance_technique)', 'Screaming', 'Screech', 'Shatter', 'Shout', 'Sigh', 'Singing', 'Sink_(filling_or_washing)', 'Siren', 'Skateboard', 'Slam', 'Sliding_door', 'Snare_drum', 'Sneeze', 'Speech', 'Speech_synthesizer', 'Splash_and_splatter', 'Squeak', 'Stream', 'Strum', 'Subway_and_metro_and_underground', 'Tabla', 'Tambourine', 'Tap', 'Tearing', 'Telephone', 'Thump_and_thud', 'Thunder', 'Thunderstorm', 'Tick', 'Tick-tock', 'Toilet_flush', 'Tools', 'Traffic_noise_and_roadway_noise', 'Train', 'Trickle_and_dribble', 'Truck', 'Trumpet', 'Typewriter', 'Typing', 'Vehicle', 'Vehicle_horn_and_car_horn_and_honking', 'Walk_and_footsteps', 'Water', 'Water_tap_and_faucet', 'Waves_and_surf', 'Whispering', 'Whoosh_and_swoosh_and_swish', 'Wild_animals', 'Wind', 'Wind_chime', 'Wind_instrument_and_woodwind_instrument', 'Wood', 'Writing', 'Yell', 'Zipper_(clothing)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare grid\n",
    "grid_size = int(np.ceil(np.sqrt(imgs.shape[0])))\n",
    "fig, axes = plt.subplots(grid_size, grid_size, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(imgs.shape[0]):\n",
    "    ax = axes[i]\n",
    "    img = imgs[i]\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    active_indices = torch.nonzero(pred[i], as_tuple=True)[0]\n",
    "    selected_labels = [col_names[i] for i in active_indices]\n",
    "\n",
    "    # get query labels\n",
    "    query_labels = torch.nonzero(test_episode['query_label'][i], as_tuple=True)[0]\n",
    "    query_label_names = [col_names[i] for i in query_labels]\n",
    "\n",
    "    ax.set_title(f\"Pred: {', '.join(selected_labels)}\\nTrue: {', '.join(query_label_names)}\", fontsize=7)\n",
    "\n",
    "for j in range(i+1, len(axes)):\n",
    "    axes[j].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = 10\n",
    "\n",
    "running_f1 = 0.0\n",
    "running_map = 0.0\n",
    "min_f1 = 1.0\n",
    "max_f1 = 0.0\n",
    "min_map = 1.0\n",
    "max_map = 0.0\n",
    "\n",
    "    # Debug counters\n",
    "zero_pred_count = 0\n",
    "zero_true_count = 0\n",
    "\n",
    "for i in tqdm(range(checks)):\n",
    "    test_ep = test_dataset.getEpisode(6, 6, 6)\n",
    "    pred, probs, true_labels, ext_true_labels, all_subsets = predict(model, test_ep, device)\n",
    "\n",
    "        # Convert to numpy for sklearn metrics\n",
    "    true_labels_np = true_labels.cpu().numpy()\n",
    "    pred_np = pred.cpu().numpy()\n",
    "    probs_np = probs.cpu().numpy()\n",
    "\n",
    "        # Debug information\n",
    "    num_pred_positives = pred_np.sum()\n",
    "    num_true_positives = true_labels_np.sum()\n",
    "\n",
    "    if num_pred_positives == 0:\n",
    "            zero_pred_count += 1\n",
    "    if num_true_positives == 0:\n",
    "            zero_true_count += 1\n",
    "\n",
    "        # Print debug info for first few episodes\n",
    "    if i < 3:\n",
    "        print(f\"\\nEpisode {i+1} Debug:\")\n",
    "        print(f\"  Pred shape: {pred_np.shape}, True shape: {true_labels_np.shape}\")\n",
    "        print(f\"  Predicted positives: {num_pred_positives}\")\n",
    "        print(f\"  True positives: {num_true_positives}\")\n",
    "        print(f\"  Prob range: [{probs_np.min():.4f}, {probs_np.max():.4f}]\")\n",
    "        print(f\"  Number of subsets: {len(all_subsets)}\")\n",
    "\n",
    "            # Show some sample predictions vs true labels\n",
    "        print(f\"  Sample predictions (first 5 queries, first 10 classes):\")\n",
    "        for q in range(min(5, pred_np.shape[0])):\n",
    "            print(f\"    Query {q}: pred={pred_np[q][:10]}, true={true_labels_np[q][:10]}\")\n",
    "\n",
    "        # Compute metrics\n",
    "    f1 = f1_score(true_labels_np, pred_np, average='macro', zero_division=0)\n",
    "    map_value = compute_mAP(true_labels_np, probs_np)\n",
    "\n",
    "        # Update running statistics\n",
    "    running_f1 += f1\n",
    "    min_f1 = min(min_f1, f1)\n",
    "    max_f1 = max(max_f1, f1)\n",
    "\n",
    "    running_map += map_value\n",
    "    min_map = min(min_map, map_value)\n",
    "    max_map = max(max_map, map_value)\n",
    "\n",
    "    # Calculate averages\n",
    "avg_f1 = running_f1 / checks\n",
    "avg_map = running_map / checks\n",
    "\n",
    "print(f\"\\n=== EVALUATION RESULTS ===\")\n",
    "print(f\"Avg F1 in test set: {avg_f1:.4f}, min: {min_f1:.4f}, max: {max_f1:.4f}\")\n",
    "print(f\"Avg mAP in test set: {avg_map:.4f}, min: {min_map:.4f}, max: {max_map:.4f}\")\n",
    "print(f\"\\n=== DEBUG INFO ===\")\n",
    "print(f\"Episodes with zero predictions: {zero_pred_count}/{checks}\")\n",
    "print(f\"Episodes with zero true labels: {zero_true_count}/{checks}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
